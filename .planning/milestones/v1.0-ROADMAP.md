# Milestone v1.0: MVP

**Status:** SHIPPED 2026-01-31
**Phases:** 1-6 (plus 3.1 inserted)
**Total Plans:** 25

## Overview

This milestone delivers a Docker-based 3D reconstruction pipeline in 7 phases (6 planned + 1 inserted), progressing from GPU-enabled infrastructure through model integration to a production-ready API. Core value: upload images, get validated 3D meshes with a single Docker command.

## Phases

### Phase 1: Foundation

**Goal**: GPU-enabled Docker environment runs with single command and responds to health checks
**Depends on**: Nothing (first phase)
**Requirements**: DEPLOY-01, DEPLOY-02, API-05
**Plans**: 1 plan

Plans:
- [x] 01-01-PLAN.md — Docker infrastructure + FastAPI health endpoint with GPU validation

**Details:**
- CUDA 11.8 → upgraded to 12.1 in Phase 3.1
- FastAPI with lifespan-based GPU validation (12GB minimum VRAM)
- Health endpoint returning live GPU memory stats
- Single-command startup via docker-compose

### Phase 2: Job Pipeline

**Goal**: Users can submit jobs, check status, and cancel jobs through async queue
**Depends on**: Phase 1
**Requirements**: DEPLOY-03, API-01, API-02, API-04
**Plans**: 4 plans

Plans:
- [x] 02-01-PLAN.md — Celery infrastructure with Redis broker
- [x] 02-02-PLAN.md — Pydantic schemas and file validation service
- [x] 02-03-PLAN.md — Job manager and Celery reconstruction task
- [x] 02-04-PLAN.md — Job API endpoints and integration

**Details:**
- Celery + Redis with dual DB architecture (DB 0 broker, DB 1 state)
- Two-step cancellation flow (request → confirm)
- Progress tracking with update_state PROGRESS
- File validation with PNG magic byte checking and size limits

### Phase 3: Model Integration

**Goal**: System runs both reconstruction models and produces textured mesh outputs
**Depends on**: Phase 2
**Requirements**: MODEL-01, MODEL-02, MODEL-03, OUT-01
**Plans**: 4 plans

Plans:
- [x] 03-01-PLAN.md — Base model interface, VRAM manager, mesh export service
- [x] 03-02-PLAN.md — Docker + PyTorch ecosystem dependencies
- [x] 03-03-PLAN.md — ReconViaGen and nvdiffrec model wrappers (STUB)
- [x] 03-04-PLAN.md — Task integration and E2E verification

**Details:**
- Model factory pattern with get_model()
- Sequential execution with VRAM cleanup between models
- STUB implementations replaced by real models in Phase 3.1

### Phase 3.1: CUDA 12 Upgrade & Real Model Integration (INSERTED)

**Goal**: Upgrade to CUDA 12.1 + PyTorch 2.4 and replace STUB implementations with real models
**Depends on**: Phase 3
**Requirements**: MODEL-01, MODEL-02 (real implementation)
**Plans**: 6 plans

Plans:
- [x] 03.1-01-PLAN.md — CUDA 12.1 + PyTorch 2.4.1 infrastructure upgrade
- [x] 03.1-02-PLAN.md — TRELLIS dependencies and pipeline wrapper
- [x] 03.1-03-PLAN.md — nvdiffrec dependencies and camera estimation
- [x] 03.1-04-PLAN.md — ReconViaGen real implementation (TRELLIS)
- [x] 03.1-05-PLAN.md — nvdiffrec real implementation (optimization loop)
- [x] 03.1-06-PLAN.md — Integration testing and verification

**Details:**
- Upgraded from CUDA 11.8 to 12.1.1
- PyTorch 2.4.1 with cu121 wheels
- ReconViaGen uses TRELLIS-VGGT pipeline
- nvdiffrec runs real optimization loop with nvdiffrast
- Pre-built flash-attn wheel for fast transformer attention

### Phase 4: Quality & Preview

**Goal**: Results include quality metrics, status classification, and preview images
**Depends on**: Phase 3.1
**Requirements**: QUAL-01, QUAL-02, QUAL-03, QUAL-04, OUT-02
**Plans**: 4 plans

Plans:
- [x] 04-01-PLAN.md — Quality metrics foundation (scikit-image, PSNR/SSIM/depth)
- [x] 04-02-PLAN.md — Mesh rendering service (nvdiffrast wrapper)
- [x] 04-03-PLAN.md — Preview generator and quality report
- [x] 04-04-PLAN.md — Pipeline integration and verification

**Details:**
- PSNR thresholds: Normal>=25dB, Warning>=20dB, Failure<20dB
- SSIM thresholds: Normal>=0.85, Warning>=0.75, Failure<0.75
- RasterizeCudaContext for GPU rendering with GL fallback
- Lazy imports to enable tests without torch

### Phase 5: Results & Error Handling

**Goal**: Users can download complete results and receive clear errors for failures
**Depends on**: Phase 4
**Requirements**: API-03, ERR-01, ERR-02, ERR-03
**Plans**: 3 plans

Plans:
- [x] 05-01-PLAN.md — Error code taxonomy and global exception handlers
- [x] 05-02-PLAN.md — Result packager service and download endpoint
- [x] 05-03-PLAN.md — Structured errors for existing endpoints and tests

**Details:**
- 17 error codes covering validation, not found, conflict, gone, model, and resource errors
- In-memory ZIP creation with StreamingResponse
- OOM detection: torch.cuda.OutOfMemoryError → MODEL_VRAM_OOM

### Phase 6: Documentation

**Goal**: Repository includes complete documentation and example outputs
**Depends on**: Phase 5
**Requirements**: DOC-01, DOC-02, DOC-03
**Plans**: 3 plans

Plans:
- [x] 06-01-PLAN.md — Core reference docs (architecture.md, API.md)
- [x] 06-02-PLAN.md — README.md with quick-start and workflow examples
- [x] 06-03-PLAN.md — Examples directory with input/output samples

**Details:**
- README with 4-step curl workflow
- Three Mermaid diagrams (architecture, data flow, cancellation)
- Symlinked sample files to avoid duplicating ~20MB of PNG data

---

## Milestone Summary

**Decimal Phases:**
- Phase 3.1: CUDA 12 Upgrade & Real Model Integration (inserted after Phase 3 for real model output)

**Key Decisions:**

- Async job queue over sync API (Model inference takes minutes)
- CUDA 12.1 over 12.4 (better spconv compatibility)
- Pre-built flash-attn wheel (source build fails)
- Two-step cancellation (prevents accidental cancellations)
- Quality failure = job failure (per requirements)
- Lazy imports via __getattr__ (tests run without torch)

**Issues Resolved:**

- STUB implementations replaced with real TRELLIS and nvdiffrec
- Import chain fixed to avoid torch at import time
- Celery task registration via explicit imports

**Issues Deferred:**

- Webhook notifications (v2 requirement)
- Batch job submission (v2 requirement)
- Additional output formats GLB/GLTF (v2 requirement)

**Technical Debt Incurred:**

- Placeholder created_at timestamp in job status (uses current time, not actual creation time)
- TODO: track actual inference duration in quality.json

---

*For current project status, see .planning/ROADMAP.md*
