---
phase: 03-model-integration
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - Dockerfile
  - requirements.txt
  - docker-compose.yml
autonomous: true

must_haves:
  truths:
    - "PyTorch with CUDA 11.8 is installed and functional"
    - "PyTorch3D is installed for mesh I/O"
    - "Model weights directory exists in container"
    - "Container builds successfully with new dependencies"
  artifacts:
    - path: "Dockerfile"
      provides: "Updated Docker image with PyTorch, PyTorch3D, model weights"
      contains: "pytorch3d"
    - path: "requirements.txt"
      provides: "Python dependencies including torch and pytorch3d"
      contains: "torch"
  key_links:
    - from: "Dockerfile"
      to: "requirements.txt"
      via: "pip install"
      pattern: "pip install.*requirements"
---

<objective>
Update Docker infrastructure with PyTorch CUDA 11.8, PyTorch3D, nvdiffrast, and model weight directories.

Purpose: Enables GPU-accelerated model inference with proper dependencies. Model weights will be pre-downloaded to avoid runtime network calls (per locked decision).

Output: Updated Dockerfile that builds with PyTorch ecosystem and creates /app/weights/ directory structure for model checkpoints.
</objective>

<execution_context>
@/home/devuser/.claude/get-shit-done/workflows/execute-plan.md
@/home/devuser/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-model-integration/03-CONTEXT.md
@.planning/phases/03-model-integration/03-RESEARCH.md

# Existing files to update
@Dockerfile
@requirements.txt
@docker-compose.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update requirements.txt with PyTorch ecosystem</name>
  <files>
    requirements.txt
  </files>
  <action>
Add PyTorch, PyTorch3D, and supporting libraries to requirements.txt.

**Update requirements.txt** (keep existing, add new):
```
# Existing dependencies (keep as-is)
fastapi==0.115.8
uvicorn[standard]==0.34.0
pydantic>=2.0
nvidia-ml-py
celery[redis]>=5.3.0,<6.0
redis>=5.0.0
pydantic-settings>=2.0.0
python-multipart>=0.0.9
aiofiles>=24.0.0
nanoid>=2.0.0
filetype>=1.2.0
pytest>=8.0.0
pytest-asyncio>=0.23.0

# Phase 3: Model integration dependencies
# PyTorch with CUDA 11.8 - installed via --index-url in Dockerfile
# torch>=2.0.0
# torchvision>=0.15.0

# 3D processing
trimesh>=4.0.0
Pillow>=10.0.0
numpy>=1.24.0
scipy>=1.11.0

# Note: pytorch3d and nvdiffrast installed from git in Dockerfile
# due to custom build requirements
```

**Important:** PyTorch and PyTorch3D require special installation (CUDA wheels, build from source) so they're installed directly in Dockerfile, not via requirements.txt. This avoids version conflicts and ensures CUDA compatibility.
  </action>
  <verify>
grep -E "trimesh|Pillow|numpy|scipy" /home/devuser/3d-obj-rendering/requirements.txt
  </verify>
  <done>
requirements.txt includes trimesh, Pillow, numpy, scipy for mesh processing support.
PyTorch ecosystem installed separately in Dockerfile for CUDA compatibility.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update Dockerfile with PyTorch and model infrastructure</name>
  <files>
    Dockerfile
  </files>
  <action>
Update Dockerfile to install PyTorch CUDA 11.8, PyTorch3D, nvdiffrast, and create weights directory.

**Replace Dockerfile with:**
```dockerfile
# GPU-enabled Python container for 3D reconstruction
# Phase 3: Added PyTorch ecosystem and model weight infrastructure
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

# Prevent interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive

# Install Python 3.10 and build essentials (needed for PyTorch3D compilation)
RUN apt-get update && apt-get install -y \
    python3.10 \
    python3.10-dev \
    python3-pip \
    curl \
    git \
    build-essential \
    ninja-build \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.10 as default
RUN update-alternatives --install /usr/bin/python python /usr/bin/python3.10 1 && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1

# Set working directory
WORKDIR /app

# Install PyTorch with CUDA 11.8 support FIRST (before other deps)
# This ensures correct CUDA version matching
RUN pip install --no-cache-dir \
    torch==2.1.0+cu118 \
    torchvision==0.16.0+cu118 \
    torchaudio==2.1.0+cu118 \
    --index-url https://download.pytorch.org/whl/cu118

# Install PyTorch3D from source (requires CUDA toolkit for compilation)
# Using pre-built wheels from pytorch3d for faster builds
RUN pip install --no-cache-dir \
    "pytorch3d @ https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py310_cu118_pyt210/pytorch3d-0.7.5-cp310-cp310-linux_x86_64.whl"

# Install nvdiffrast (NVIDIA's differentiable rasterizer)
RUN pip install --no-cache-dir git+https://github.com/NVlabs/nvdiffrast/

# Copy and install remaining Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Create model weights directory structure
# Weights will be downloaded and cached here
RUN mkdir -p /app/weights/reconviagen /app/weights/nvdiffrec

# Copy application code
COPY app/ app/

# Create storage directories
RUN mkdir -p /app/storage/jobs

# Expose API port
EXPOSE 8000

# Use exec form CMD for proper signal handling
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Key changes:**
1. Added git, build-essential, ninja-build for PyTorch3D compilation
2. Install PyTorch with CUDA 11.8 wheels before other packages
3. Install PyTorch3D from pre-built wheel (faster than source compilation)
4. Install nvdiffrast from git
5. Create /app/weights/ directory structure for model checkpoints
6. Create /app/storage/jobs directory

**Note on model weights:** Actual weight downloads will be added in a later plan when we know exact checkpoint URLs. For now, the directory structure is created.
  </action>
  <verify>
grep -E "pytorch3d|nvdiffrast|weights" /home/devuser/3d-obj-rendering/Dockerfile
  </verify>
  <done>
Dockerfile installs PyTorch 2.1.0 with CUDA 11.8, PyTorch3D 0.7.5, nvdiffrast.
/app/weights/ directory created for model checkpoints.
Build dependencies (git, ninja-build) included.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update docker-compose.yml with increased shared memory</name>
  <files>
    docker-compose.yml
  </files>
  <action>
Update docker-compose.yml to increase shared memory for PyTorch DataLoader and add weights volume.

**Read current docker-compose.yml and add/update:**

1. Add `shm_size: '8gb'` to api service (PyTorch DataLoader needs shared memory)
2. Add weights volume for persistent model weights across rebuilds
3. Ensure proper GPU configuration maintained

The key additions:
- `shm_size: '8gb'` - PyTorch uses /dev/shm for multiprocessing
- Named volume for weights (optional, helps avoid re-downloading)

Update the api and worker services to include:
```yaml
    shm_size: '8gb'
    volumes:
      - job_storage:/app/storage/jobs
      - model_weights:/app/weights
```

And add to volumes section:
```yaml
volumes:
  job_storage:
  model_weights:
```
  </action>
  <verify>
grep -E "shm_size|model_weights" /home/devuser/3d-obj-rendering/docker-compose.yml
  </verify>
  <done>
docker-compose.yml has 8GB shared memory for PyTorch multiprocessing.
model_weights volume added for persistent model checkpoint storage.
  </done>
</task>

</tasks>

<verification>
After all tasks:
1. `docker-compose build` completes successfully (may take 10-20 min for PyTorch3D)
2. Container starts and PyTorch CUDA is available:
   `docker-compose run --rm api python -c "import torch; print(torch.cuda.is_available())"`
3. PyTorch3D importable:
   `docker-compose run --rm api python -c "import pytorch3d; print('OK')"`
4. Weights directory exists:
   `docker-compose run --rm api ls -la /app/weights/`

Note: Full Docker build testing may be deferred to integration plan (03-04) due to long build times.
</verification>

<success_criteria>
- requirements.txt includes trimesh, Pillow, numpy, scipy
- Dockerfile installs PyTorch 2.1.0+cu118, PyTorch3D, nvdiffrast
- Dockerfile creates /app/weights/ directory structure
- docker-compose.yml has shm_size: '8gb' and model_weights volume
- Configuration follows existing patterns (exec form CMD, proper layering)
</success_criteria>

<output>
After completion, create `.planning/phases/03-model-integration/03-02-SUMMARY.md`
</output>
