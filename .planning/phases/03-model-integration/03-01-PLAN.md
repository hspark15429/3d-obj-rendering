---
phase: 03-model-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - app/models/__init__.py
  - app/models/base.py
  - app/services/vram_manager.py
  - app/services/mesh_export.py
autonomous: true

must_haves:
  truths:
    - "Base model class exists with standard interface (load_weights, inference, report_progress)"
    - "VRAM cleanup function properly releases GPU memory"
    - "Mesh export creates both OBJ and PLY formats with textures"
  artifacts:
    - path: "app/models/base.py"
      provides: "Abstract base class for reconstruction models"
      exports: ["BaseReconstructionModel"]
      min_lines: 40
    - path: "app/services/vram_manager.py"
      provides: "GPU memory management utilities"
      exports: ["cleanup_gpu_memory", "check_vram_available"]
      min_lines: 30
    - path: "app/services/mesh_export.py"
      provides: "Mesh export with PyTorch3D"
      exports: ["save_mesh_both_formats", "validate_mesh_output"]
      min_lines: 50
  key_links:
    - from: "app/models/base.py"
      to: "app/services/vram_manager.py"
      via: "import cleanup_gpu_memory"
      pattern: "from app\\.services\\.vram_manager import"
    - from: "app/services/mesh_export.py"
      to: "pytorch3d.io"
      via: "save_obj, save_ply functions"
      pattern: "from pytorch3d\\.io import"
---

<objective>
Create foundational infrastructure for model integration: abstract base class for reconstruction models, VRAM management utilities, and mesh export service using PyTorch3D.

Purpose: Provides standardized interfaces that ReconViaGen and nvdiffrec wrappers will implement, plus utilities for VRAM cleanup between sequential model runs and mesh export in OBJ/PLY formats with textures.

Output: Three new modules (app/models/base.py, app/services/vram_manager.py, app/services/mesh_export.py) ready for model wrapper implementation.
</objective>

<execution_context>
@/home/devuser/.claude/get-shit-done/workflows/execute-plan.md
@/home/devuser/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-model-integration/03-CONTEXT.md
@.planning/phases/03-model-integration/03-RESEARCH.md

# Existing code to extend
@app/tasks/reconstruction.py
@app/services/file_handler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create model base class and VRAM manager</name>
  <files>
    app/models/__init__.py
    app/models/base.py
    app/services/vram_manager.py
  </files>
  <action>
Create app/models/ package with abstract base class for reconstruction models.

**app/models/base.py:**
```python
from abc import ABC, abstractmethod
from typing import Optional
from pathlib import Path

class BaseReconstructionModel(ABC):
    """Abstract base for reconstruction models (ReconViaGen, nvdiffrec)."""

    model_name: str = "base"  # Override in subclasses

    def __init__(self, celery_task=None):
        self.celery_task = celery_task
        self._model = None

    @abstractmethod
    def load_weights(self) -> None:
        """Load pre-downloaded model weights from /app/weights/."""
        pass

    @abstractmethod
    def inference(self, input_dir: Path, output_dir: Path) -> dict:
        """
        Run inference on input images, produce mesh output.

        Args:
            input_dir: Path containing views/ and depth/ subdirectories
            output_dir: Path to write mesh.obj, mesh.ply, texture.png

        Returns:
            dict with 'status' ('success'/'failed'), 'error' (if failed),
            'mesh_path', 'texture_path' (if success)
        """
        pass

    def report_progress(self, progress: int, step: str) -> None:
        """Report progress to Celery task."""
        if self.celery_task:
            self.celery_task.update_state(
                state='PROGRESS',
                meta={
                    'progress': progress,
                    'step': f'{self.model_name}: {step}'
                }
            )

    def cleanup(self) -> None:
        """Release model resources. Call after inference completes."""
        if self._model is not None:
            del self._model
            self._model = None
```

**app/services/vram_manager.py:**
```python
import gc
import logging
import torch

logger = logging.getLogger(__name__)

def cleanup_gpu_memory() -> dict:
    """
    Complete GPU memory cleanup pattern.

    Order matters:
    1. Force Python garbage collection
    2. Clear PyTorch's caching allocator

    Returns:
        dict with 'allocated_gb' and 'reserved_gb' after cleanup
    """
    gc.collect()
    torch.cuda.empty_cache()

    allocated = torch.cuda.memory_allocated() / (1024**3)
    reserved = torch.cuda.memory_reserved() / (1024**3)

    logger.info(f"VRAM after cleanup: {allocated:.2f}GB allocated, {reserved:.2f}GB reserved")

    return {
        'allocated_gb': round(allocated, 2),
        'reserved_gb': round(reserved, 2)
    }

def check_vram_available(required_gb: float = 10.0) -> dict:
    """
    Check if sufficient VRAM is available.

    Args:
        required_gb: Minimum required VRAM in GB (default 10GB)

    Returns:
        dict with 'available': bool, 'free_gb': float, 'total_gb': float
    """
    if not torch.cuda.is_available():
        return {'available': False, 'free_gb': 0, 'total_gb': 0, 'error': 'CUDA not available'}

    total = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    allocated = torch.cuda.memory_allocated() / (1024**3)
    free = total - allocated

    return {
        'available': free >= required_gb,
        'free_gb': round(free, 2),
        'total_gb': round(total, 2),
        'allocated_gb': round(allocated, 2)
    }

def get_vram_usage() -> dict:
    """Get current VRAM usage stats."""
    if not torch.cuda.is_available():
        return {'error': 'CUDA not available'}

    return {
        'allocated_gb': round(torch.cuda.memory_allocated() / (1024**3), 2),
        'reserved_gb': round(torch.cuda.memory_reserved() / (1024**3), 2),
        'total_gb': round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)
    }
```

**app/models/__init__.py:**
```python
"""3D reconstruction model wrappers."""
from app.models.base import BaseReconstructionModel

__all__ = ['BaseReconstructionModel']
```

Note: torch import in vram_manager.py will require PyTorch in requirements (Plan 02 handles this).
  </action>
  <verify>
python -c "from app.models.base import BaseReconstructionModel; print('Base class OK')"
python -c "import app.services.vram_manager as vm; print(vm.cleanup_gpu_memory.__doc__[:20])"
  </verify>
  <done>
BaseReconstructionModel abstract class exists with load_weights(), inference(), report_progress(), cleanup() methods.
VRAM manager exports cleanup_gpu_memory() and check_vram_available() functions.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create mesh export service with PyTorch3D</name>
  <files>
    app/services/mesh_export.py
  </files>
  <action>
Create mesh export service using PyTorch3D for OBJ/PLY output with textures.

**app/services/mesh_export.py:**
```python
"""
Mesh export service using PyTorch3D.

Exports meshes in both OBJ (with MTL and texture) and PLY formats.
"""
import logging
from pathlib import Path
from typing import Optional

import torch
from PIL import Image
import numpy as np

logger = logging.getLogger(__name__)


def save_mesh_both_formats(
    verts: torch.Tensor,
    faces: torch.Tensor,
    texture_map: Optional[torch.Tensor],
    verts_uvs: Optional[torch.Tensor],
    output_dir: Path,
    mesh_name: str = "mesh"
) -> dict:
    """
    Save mesh in both OBJ and PLY formats with texture.

    Args:
        verts: FloatTensor (V, 3) - vertex positions
        faces: LongTensor (F, 3) - face indices (0-indexed)
        texture_map: Optional FloatTensor (H, W, 3) in [0, 1] - RGB texture
        verts_uvs: Optional FloatTensor (V, 2) - UV coordinates per vertex
        output_dir: Path to output directory
        mesh_name: Base name for output files (default: "mesh")

    Returns:
        dict with 'obj_path', 'ply_path', 'texture_path' (if texture provided)
    """
    from pytorch3d.io import save_obj, save_ply

    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    result = {}

    # Ensure tensors are on CPU for file I/O
    verts = verts.cpu() if verts.is_cuda else verts
    faces = faces.cpu() if faces.is_cuda else faces

    obj_path = output_dir / f"{mesh_name}.obj"
    ply_path = output_dir / f"{mesh_name}.ply"

    # Save OBJ with texture if provided
    if texture_map is not None and verts_uvs is not None:
        texture_map = texture_map.cpu() if texture_map.is_cuda else texture_map
        verts_uvs = verts_uvs.cpu() if verts_uvs.is_cuda else verts_uvs

        # PyTorch3D save_obj with texture
        save_obj(
            f=str(obj_path),
            verts=verts,
            faces=faces,
            verts_uvs=verts_uvs,
            faces_uvs=faces,  # Assumes 1:1 vertex-to-UV mapping
            texture_map=texture_map,
            decimal_places=6
        )

        # Texture is saved automatically as mesh_name.png by save_obj
        texture_path = output_dir / f"{mesh_name}.png"
        result['texture_path'] = str(texture_path)

        logger.info(f"Saved OBJ with texture: {obj_path}")
    else:
        # Save OBJ without texture
        save_obj(
            f=str(obj_path),
            verts=verts,
            faces=faces,
            decimal_places=6
        )
        logger.info(f"Saved OBJ without texture: {obj_path}")

    result['obj_path'] = str(obj_path)

    # Save PLY (binary format for smaller files)
    save_ply(
        f=str(ply_path),
        verts=verts,
        faces=faces,
        ascii=False,
        decimal_places=6
    )
    result['ply_path'] = str(ply_path)

    logger.info(f"Saved PLY: {ply_path}")

    return result


def save_texture_image(
    texture: torch.Tensor,
    output_path: Path
) -> str:
    """
    Save texture tensor as PNG image.

    Args:
        texture: FloatTensor (H, W, 3) in [0, 1] range
        output_path: Path for output PNG

    Returns:
        str: Path to saved texture
    """
    output_path = Path(output_path)

    # Convert to numpy and scale to 0-255
    texture = texture.cpu() if texture.is_cuda else texture
    texture_np = (texture.numpy() * 255).astype(np.uint8)

    # Save as PNG
    Image.fromarray(texture_np).save(str(output_path))
    logger.info(f"Saved texture: {output_path}")

    return str(output_path)


def validate_mesh_output(output_dir: Path, mesh_name: str = "mesh") -> dict:
    """
    Validate mesh output files exist and are non-empty.

    Args:
        output_dir: Directory containing mesh files
        mesh_name: Base name of mesh files

    Returns:
        dict with 'valid': bool, 'files': dict of file paths and sizes,
        'error': str if invalid
    """
    output_dir = Path(output_dir)

    required_files = [
        (f"{mesh_name}.obj", "OBJ mesh"),
        (f"{mesh_name}.ply", "PLY mesh"),
    ]

    optional_files = [
        (f"{mesh_name}.mtl", "Material file"),
        (f"{mesh_name}.png", "Texture image"),
    ]

    files = {}
    errors = []

    # Check required files
    for filename, description in required_files:
        file_path = output_dir / filename
        if not file_path.exists():
            errors.append(f"Missing {description}: {filename}")
        elif file_path.stat().st_size == 0:
            errors.append(f"Empty {description}: {filename}")
        else:
            files[filename] = {
                'path': str(file_path),
                'size_bytes': file_path.stat().st_size
            }

    # Check optional files (just note if present)
    for filename, description in optional_files:
        file_path = output_dir / filename
        if file_path.exists() and file_path.stat().st_size > 0:
            files[filename] = {
                'path': str(file_path),
                'size_bytes': file_path.stat().st_size
            }

    if errors:
        return {
            'valid': False,
            'files': files,
            'error': '; '.join(errors)
        }

    return {
        'valid': True,
        'files': files
    }
```

Note: Requires pytorch3d, PIL (Pillow), numpy in requirements (Plan 02 handles dependencies).
  </action>
  <verify>
python -c "from app.services.mesh_export import save_mesh_both_formats, validate_mesh_output; print('Mesh export OK')"
  </verify>
  <done>
Mesh export service exists with save_mesh_both_formats() for OBJ/PLY output and validate_mesh_output() for checking results.
PyTorch3D integration handles textures and MTL file creation.
  </done>
</task>

</tasks>

<verification>
All verification commands pass:
- Base model class importable and has required methods
- VRAM manager functions importable
- Mesh export service importable with both key functions

Note: Full functionality testing requires PyTorch3D which will be installed by Plan 02.
</verification>

<success_criteria>
- app/models/base.py exports BaseReconstructionModel with abstract methods
- app/services/vram_manager.py exports cleanup_gpu_memory, check_vram_available
- app/services/mesh_export.py exports save_mesh_both_formats, validate_mesh_output
- All modules follow established project patterns (type hints, docstrings, logging)
</success_criteria>

<output>
After completion, create `.planning/phases/03-model-integration/03-01-SUMMARY.md`
</output>
