---
phase: 03.1-cuda-12-upgrade
plan: 06
type: execute
wave: 4
depends_on: ["03.1-04", "03.1-05"]
files_modified:
  - tests/test_models.py
autonomous: false

must_haves:
  truths:
    - "Both models load and run without errors on GPU"
    - "ReconViaGen produces mesh with real geometry (not cube)"
    - "nvdiffrec produces mesh with optimized geometry (not placeholder sphere)"
    - "All existing tests pass with upgraded dependencies"
  artifacts:
    - path: "tests/test_models.py"
      provides: "Model integration tests"
      min_lines: 50
  key_links:
    - from: "tests/test_models.py"
      to: "app/models/__init__.py"
      via: "get_model import"
      pattern: "from app.models import get_model"
---

<objective>
Verify both real model implementations work end-to-end with test data

Purpose: Confirm Phase 3.1 success criteria - real models produce actual textured meshes
Output: Verified models, integration tests, human confirmation of mesh quality
</objective>

<execution_context>
@/home/devuser/.claude/get-shit-done/workflows/execute-plan.md
@/home/devuser/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/03.1-cuda-12-upgrade-real-model-integration/03.1-RESEARCH.md
@.planning/phases/03.1-cuda-12-upgrade-real-model-integration/03.1-04-SUMMARY.md
@.planning/phases/03.1-cuda-12-upgrade-real-model-integration/03.1-05-SUMMARY.md
@app/models/__init__.py
@tests/test_file_handler.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create model integration tests</name>
  <files>tests/test_models.py</files>
  <action>
Create integration tests for both model implementations:

```python
"""
Integration tests for 3D reconstruction models.

Tests verify:
- Model loading and initialization
- Inference with test data
- Output mesh validation
"""
import os
import pytest
import tempfile
from pathlib import Path
from unittest.mock import MagicMock, patch

import numpy as np
from PIL import Image


# Skip tests if no GPU available
def gpu_available():
    try:
        import torch
        return torch.cuda.is_available()
    except ImportError:
        return False


pytestmark = pytest.mark.skipif(
    not gpu_available(),
    reason="GPU not available"
)


@pytest.fixture
def test_input_dir():
    """Create test input directory with dummy images."""
    with tempfile.TemporaryDirectory() as tmpdir:
        input_dir = Path(tmpdir) / "input"
        views_dir = input_dir / "views"
        depth_dir = input_dir / "depth"

        views_dir.mkdir(parents=True)
        depth_dir.mkdir(parents=True)

        # Create 6 dummy view images (256x256 RGB)
        for i in range(6):
            img = Image.new('RGB', (256, 256), color=(100 + i*20, 100, 100))
            img.save(views_dir / f"view_{i:02d}.png")

        # Create 6 dummy depth images (256x256 grayscale)
        for i in range(6):
            depth = Image.new('L', (256, 256), color=128)
            depth.save(depth_dir / f"depth_{i:02d}.png")

        yield input_dir


@pytest.fixture
def test_output_dir():
    """Create test output directory."""
    with tempfile.TemporaryDirectory() as tmpdir:
        yield Path(tmpdir) / "output"


class TestModelFactory:
    """Tests for model factory function."""

    def test_available_models_list(self):
        """AVAILABLE_MODELS contains expected models."""
        from app.models import AVAILABLE_MODELS

        assert 'reconviagen' in AVAILABLE_MODELS
        assert 'nvdiffrec' in AVAILABLE_MODELS

    def test_get_reconviagen_model(self):
        """get_model returns ReconViaGenModel for 'reconviagen'."""
        from app.models import get_model
        from app.models.reconviagen import ReconViaGenModel

        model = get_model('reconviagen')
        assert isinstance(model, ReconViaGenModel)
        assert model.model_name == 'reconviagen'

    def test_get_nvdiffrec_model(self):
        """get_model returns NvdiffrecModel for 'nvdiffrec'."""
        from app.models import get_model
        from app.models.nvdiffrec import NvdiffrecModel

        model = get_model('nvdiffrec')
        assert isinstance(model, NvdiffrecModel)
        assert model.model_name == 'nvdiffrec'

    def test_get_invalid_model_raises(self):
        """get_model raises ValueError for unknown model."""
        from app.models import get_model

        with pytest.raises(ValueError):
            get_model('unknown_model')


class TestReconViaGenModel:
    """Tests for ReconViaGen model."""

    def test_model_instantiation(self):
        """ReconViaGenModel can be instantiated."""
        from app.models.reconviagen import ReconViaGenModel

        model = ReconViaGenModel()
        assert model.model_name == 'reconviagen'
        assert model._pipeline is None  # Not loaded yet

    def test_vram_requirement(self):
        """Model declares VRAM requirement."""
        from app.models.reconviagen import REQUIRED_VRAM_GB

        assert REQUIRED_VRAM_GB >= 12  # TRELLIS needs significant VRAM

    @pytest.mark.slow
    def test_inference_produces_mesh(self, test_input_dir, test_output_dir):
        """
        Full inference test - produces real mesh file.

        Note: This test requires model weights to be downloaded.
        Skipped if weights not available.
        """
        from app.models.reconviagen import ReconViaGenModel, WEIGHTS_PATH

        # Skip if weights not available
        if not (WEIGHTS_PATH / "trellis-vggt").exists():
            pytest.skip("Model weights not downloaded")

        model = ReconViaGenModel()
        model.load_weights()

        result = model.inference(test_input_dir, test_output_dir)

        assert result['status'] == 'success'
        assert 'mesh_path' in result
        assert Path(result['mesh_path']).exists()


class TestNvdiffrecModel:
    """Tests for nvdiffrec model."""

    def test_model_instantiation(self):
        """NvdiffrecModel can be instantiated."""
        from app.models.nvdiffrec import NvdiffrecModel

        model = NvdiffrecModel()
        assert model.model_name == 'nvdiffrec'
        assert model._glctx is None  # Not initialized yet

    def test_custom_iterations(self):
        """Model accepts custom iteration count."""
        from app.models.nvdiffrec import NvdiffrecModel

        model = NvdiffrecModel(iterations=100)
        assert model._iterations == 100

    def test_vram_requirement(self):
        """Model declares VRAM requirement."""
        from app.models.nvdiffrec import REQUIRED_VRAM_GB

        assert REQUIRED_VRAM_GB >= 10  # Optimization needs VRAM

    @pytest.mark.slow
    def test_inference_produces_mesh(self, test_input_dir, test_output_dir):
        """
        Full inference test - runs optimization and produces mesh.

        Uses reduced iterations for testing speed.
        """
        from app.models.nvdiffrec import NvdiffrecModel

        model = NvdiffrecModel(iterations=50)  # Fast test
        model.load_weights()

        result = model.inference(test_input_dir, test_output_dir)

        assert result['status'] == 'success'
        assert 'mesh_path' in result
        assert Path(result['mesh_path']).exists()
        assert result.get('iterations', 0) > 0


class TestCameraEstimation:
    """Tests for camera estimation service."""

    def test_look_at_matrix_shape(self):
        """look_at_matrix returns 4x4 matrix."""
        from app.services.camera_estimation import look_at_matrix

        mat = look_at_matrix([0, 0, 2.5], [0, 0, 0], [0, 1, 0])
        assert mat.shape == (4, 4)

    def test_look_at_matrix_orthogonal(self):
        """look_at_matrix produces orthogonal rotation."""
        from app.services.camera_estimation import look_at_matrix
        import numpy as np

        mat = look_at_matrix([0, 0, 2.5], [0, 0, 0], [0, 1, 0])
        rotation = mat[:3, :3]

        # Check orthogonality: R @ R.T should be identity
        identity = rotation @ rotation.T
        np.testing.assert_array_almost_equal(identity, np.eye(3), decimal=5)

    def test_create_nerf_dataset(self, test_input_dir):
        """create_nerf_dataset produces valid NeRF format."""
        from app.services.camera_estimation import create_nerf_dataset, validate_nerf_dataset

        with tempfile.TemporaryDirectory() as tmpdir:
            output_dir = Path(tmpdir)

            result = create_nerf_dataset(
                views_dir=test_input_dir / "views",
                depth_dir=test_input_dir / "depth",
                output_dir=output_dir,
                image_size=256,
            )

            assert result['status'] == 'success'
            assert result['image_count'] == 6

            # Validate the created dataset
            validation = validate_nerf_dataset(output_dir)
            assert validation['valid']
            assert validation['frame_count'] == 6
```

This test file:
- Tests model factory function
- Tests model instantiation (fast, no GPU needed for basic tests)
- Tests full inference with @pytest.mark.slow (requires GPU + weights)
- Tests camera estimation service
  </action>
  <verify>
Run: `pytest tests/test_models.py -v --ignore-glob="*slow*" -k "not slow"`
Check: Fast tests pass (factory, instantiation, camera estimation)
  </verify>
  <done>Model integration tests created</done>
</task>

<task type="auto">
  <name>Task 2: Run full model verification</name>
  <files></files>
  <action>
Build final Docker image and run all verification steps:

1. Build complete image:
```bash
docker build -t 3d-recon:phase3.1 .
```

2. Run all fast tests:
```bash
docker run --gpus all --rm 3d-recon:phase3.1 pytest tests/ -v -k "not slow"
```

3. Verify both models can initialize:
```bash
docker run --gpus all --rm 3d-recon:phase3.1 python -c "
from app.models import get_model, AVAILABLE_MODELS
print(f'Available models: {AVAILABLE_MODELS}')

# Test ReconViaGen initialization
rv = get_model('reconviagen')
print(f'ReconViaGen: {rv.model_name}')

# Test nvdiffrec initialization
nv = get_model('nvdiffrec', iterations=10)
print(f'nvdiffrec: {nv.model_name}, iterations={nv._iterations}')

# Initialize nvdiffrec (doesn't need weights)
nv.load_weights()
print('nvdiffrec initialized successfully')
print('Both models ready')
"
```

4. Verify CUDA stack is correct:
```bash
docker run --gpus all --rm 3d-recon:phase3.1 python -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA: {torch.version.cuda}')
print(f'GPU: {torch.cuda.get_device_name(0)}')

import nvdiffrast.torch as dr
print('nvdiffrast: OK')

import spconv.pytorch as spconv
print(f'spconv: {spconv.__version__}')

print('\\nAll Phase 3.1 dependencies verified!')
"
```

5. Create test meshes (optional - verifies output generation):
```bash
docker run --gpus all --rm -v $(pwd)/test_output:/app/test_output 3d-recon:phase3.1 python -c "
import tempfile
from pathlib import Path
from PIL import Image
import numpy as np

# Create minimal test input
with tempfile.TemporaryDirectory() as tmpdir:
    input_dir = Path(tmpdir)
    views_dir = input_dir / 'views'
    depth_dir = input_dir / 'depth'
    views_dir.mkdir()
    depth_dir.mkdir()

    # Create dummy images
    for i in range(6):
        img = Image.fromarray(np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8))
        img.save(views_dir / f'view_{i:02d}.png')
        depth = Image.fromarray(np.random.randint(50, 200, (256, 256), dtype=np.uint8))
        depth.save(depth_dir / f'depth_{i:02d}.png')

    # Test nvdiffrec (fast with few iterations)
    from app.models import get_model
    output_dir = Path('/app/test_output/nvdiffrec')
    output_dir.mkdir(parents=True, exist_ok=True)

    model = get_model('nvdiffrec', iterations=20)
    model.load_weights()
    result = model.inference(input_dir, output_dir)
    print(f'nvdiffrec result: {result[\"status\"]}')
    if result['status'] == 'success':
        print(f'Mesh: {result[\"mesh_path\"]}')
"
```
  </action>
  <verify>
- Docker build succeeds
- All fast tests pass
- Both models initialize without errors
- CUDA 12.1 + PyTorch 2.4.1 stack verified
- nvdiffrec can produce output mesh (optional)
  </verify>
  <done>Full model verification complete</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>
CUDA 12.1 + PyTorch 2.4.1 infrastructure upgrade and real model implementations:
- Dockerfile with all dependencies (spconv, xformers, flash-attn, tiny-cuda-nn)
- ReconViaGen using TRELLIS-VGGT pipeline
- nvdiffrec using optimization loop with camera estimation
- Integration tests for both models
  </what-built>
  <how-to-verify>
1. Build and start the container:
   ```bash
   docker-compose up --build -d
   ```

2. Check API health:
   ```bash
   curl http://localhost:8000/health
   ```
   Expected: {"status": "healthy", "gpu_available": true, ...}

3. Submit a test job (if you have test images):
   ```bash
   curl -X POST http://localhost:8000/jobs \
     -F "model=nvdiffrec" \
     -F "multi_views=@test_data.zip"
   ```

4. Check container logs for any errors:
   ```bash
   docker-compose logs api worker
   ```

5. Verify no CUDA errors or import failures in logs

Note: Full ReconViaGen testing requires downloading ~5GB of model weights.
nvdiffrec works without pre-trained weights (optimizes from scratch).
  </how-to-verify>
  <resume-signal>
Type "approved" if infrastructure works correctly
Or describe any issues encountered
  </resume-signal>
</task>

</tasks>

<verification>
- All pytest tests pass
- Both models initialize on GPU
- Docker container builds and runs
- API health endpoint shows GPU available
- No import errors in container logs
</verification>

<success_criteria>
- tests/test_models.py created with comprehensive tests
- All fast tests pass
- Docker build completes successfully
- Models can be initialized and used
- Human verification confirms working infrastructure
</success_criteria>

<output>
After completion, create `.planning/phases/03.1-cuda-12-upgrade-real-model-integration/03.1-06-SUMMARY.md`
</output>
