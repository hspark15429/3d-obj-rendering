---
phase: 03.1-cuda-12-upgrade
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - Dockerfile
  - requirements.txt
autonomous: true

must_haves:
  truths:
    - "Docker container builds successfully with CUDA 12.1"
    - "PyTorch 2.4.1 loads and detects CUDA"
    - "nvdiffrast compiles and imports without errors"
  artifacts:
    - path: "Dockerfile"
      provides: "CUDA 12.1 base image with PyTorch 2.4.1"
      contains: "nvidia/cuda:12.1"
    - path: "requirements.txt"
      provides: "Updated dependencies with numpy<2 pin"
      contains: "numpy<2"
  key_links:
    - from: "Dockerfile"
      to: "PyTorch CUDA wheels"
      via: "--index-url https://download.pytorch.org/whl/cu121"
      pattern: "cu121"
---

<objective>
Upgrade Docker infrastructure from CUDA 11.8 + PyTorch 2.1 to CUDA 12.1 + PyTorch 2.4.1

Purpose: Enable installation of ReconViaGen dependencies (spconv-cu120, xformers, flash-attn) which require CUDA 12.x
Output: Dockerfile that builds successfully with new CUDA/PyTorch stack
</objective>

<execution_context>
@/home/devuser/.claude/get-shit-done/workflows/execute-plan.md
@/home/devuser/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03.1-cuda-12-upgrade-real-model-integration/03.1-RESEARCH.md
@Dockerfile
@requirements.txt
</context>

<tasks>

<task type="auto">
  <name>Task 1: Upgrade Dockerfile to CUDA 12.1 + PyTorch 2.4.1</name>
  <files>Dockerfile</files>
  <action>
Update Dockerfile with:

1. Change base image from `nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04` to `nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04`

2. Update PyTorch installation to:
```dockerfile
RUN pip install --no-cache-dir \
    torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 \
    --index-url https://download.pytorch.org/whl/cu121
```

3. Remove PyTorch3D wheel installation (cu118 wheel won't work with cu121). Add comment that PyTorch3D will be addressed in Phase 3.1-02.

4. Keep nvdiffrast installation with --no-build-isolation flag (required for CUDA extension build)

5. Update TORCH_CUDA_ARCH_LIST to include newer architectures: "7.0;7.5;8.0;8.6;8.9;9.0"

6. Add numpy<2 pin BEFORE nvdiffrast to avoid ABI incompatibility:
```dockerfile
RUN pip install --no-cache-dir "numpy<2"
```

7. Update comment at top to indicate Phase 3.1 upgrade
  </action>
  <verify>
Run: `docker build -t 3d-recon-test:cuda12 .` (may take 10-15 minutes)
Check: Build completes without errors
  </verify>
  <done>Dockerfile updated with CUDA 12.1 base, PyTorch 2.4.1, and builds successfully</done>
</task>

<task type="auto">
  <name>Task 2: Update requirements.txt for CUDA 12 compatibility</name>
  <files>requirements.txt</files>
  <action>
Update requirements.txt:

1. Add explicit numpy<2 pin (first in 3D processing section):
```
# 3D processing - numpy<2 required for spconv/nvdiffrast compatibility
numpy>=1.24.0,<2
```

2. Update comment about PyTorch installation to reference CUDA 12.1

3. Add placeholder comments for Phase 3.1 dependencies that will be added in subsequent plans:
```
# Phase 3.1: Additional dependencies (added in 03.1-02 and 03.1-03)
# spconv-cu120, xformers, flash-attn, tiny-cuda-nn
```

4. Keep all existing dependencies (fastapi, celery, trimesh, etc.)
  </action>
  <verify>
Run: `pip check` in container to verify no dependency conflicts
Run: `python -c "import numpy; print(numpy.__version__)"` - should be < 2.0
  </verify>
  <done>requirements.txt updated with numpy<2 pin and CUDA 12 compatibility notes</done>
</task>

<task type="auto">
  <name>Task 3: Verify CUDA/PyTorch stack works</name>
  <files></files>
  <action>
Build and test the updated Docker image:

1. Build the image:
```bash
docker build -t 3d-recon-test:cuda12 .
```

2. Run verification commands in container:
```bash
docker run --gpus all --rm 3d-recon-test:cuda12 python -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA version: {torch.version.cuda}')
print(f'cuDNN version: {torch.backends.cudnn.version()}')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    t = torch.tensor([1.0]).cuda()
    print(f'Tensor on GPU: {t.device}')
"
```

3. Test nvdiffrast import:
```bash
docker run --gpus all --rm 3d-recon-test:cuda12 python -c "
import nvdiffrast.torch as dr
print('nvdiffrast imported successfully')
"
```

4. Test existing tests still pass:
```bash
docker run --gpus all --rm 3d-recon-test:cuda12 pytest tests/ -v
```
  </action>
  <verify>
All verification commands succeed:
- PyTorch 2.4.1 with CUDA 12.1
- GPU detected and tensor operations work
- nvdiffrast imports without errors
- Existing tests pass
  </verify>
  <done>CUDA 12.1 + PyTorch 2.4.1 stack verified working with GPU support</done>
</task>

</tasks>

<verification>
- Docker build completes without errors
- `torch.cuda.is_available()` returns True
- `torch.version.cuda` shows 12.1
- nvdiffrast imports successfully
- Existing tests pass
</verification>

<success_criteria>
- Dockerfile uses CUDA 12.1 base image
- PyTorch 2.4.1 installed with cu121 wheels
- numpy pinned to <2 for compatibility
- Container builds and runs with GPU access
- No regression in existing functionality
</success_criteria>

<output>
After completion, create `.planning/phases/03.1-cuda-12-upgrade-real-model-integration/03.1-01-SUMMARY.md`
</output>
