# Phase 3.1: CUDA 12 Upgrade & Real Model Integration - Research

**Researched:** 2026-01-31
**Domain:** CUDA/PyTorch ecosystem upgrade, 3D reconstruction model integration
**Confidence:** MEDIUM (ReconViaGen code availability uncertain, nvdiffrec well-documented)

## Summary

This phase requires upgrading from CUDA 11.8 + PyTorch 2.1 to CUDA 12.1 + PyTorch 2.4, then replacing STUB implementations with real ReconViaGen and nvdiffrec models. The research reveals several critical findings:

1. **PyTorch 2.4 does NOT have CUDA 12.0 wheels** - only CUDA 12.1 and 12.4 are available. The phase requirement of "CUDA 12.0" should be adjusted to CUDA 12.1 for compatibility.

2. **ReconViaGen official code is NOT released** - the GAP-LAB repo states "code open source process is stuck in company review." However, an unofficial implementation exists via Stable-X on Hugging Face that uses TRELLIS + VGGT architecture with pre-built wheels.

3. **nvdiffrec is well-documented** and requires tiny-cuda-nn plus a NeRF-format dataset structure (transforms_train.json with camera poses).

**Primary recommendation:** Use CUDA 12.1 (not 12.0), leverage the Stable-X/ReconViaGen Hugging Face Space implementation for ReconViaGen, and implement nvdiffrec using official NVIDIA repo patterns.

## Standard Stack

The established libraries/tools for this domain:

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| PyTorch | 2.4.1+cu121 | Deep learning framework | Latest stable with CUDA 12.1 support |
| torchvision | 0.19.1 | Image processing | Matches PyTorch 2.4.1 |
| CUDA Toolkit | 12.1 | GPU compute | PyTorch 2.4 has wheels for 12.1 (not 12.0) |
| nvdiffrast | 0.3.3 | Differentiable rasterization | NVIDIA official, required for nvdiffrec |
| spconv-cu120 | 2.3.6 | Sparse convolutions | Required for TRELLIS/ReconViaGen |
| xformers | 0.0.27.post2 | Memory-efficient attention | Required for TRELLIS, specific version pinned |
| flash-attn | 2.7.0.post2 | Fast attention | Pre-built wheel for cu12+torch2.4 available |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| tiny-cuda-nn | latest (git) | Neural network primitives | Required by nvdiffrec |
| trimesh | 4.5.3 | Mesh I/O and processing | Mesh export/validation |
| transformers | 4.46.3 | Vision transformers | VGGT model backbone |
| einops | 0.8.1 | Tensor operations | Required by attention layers |
| huggingface_hub | 0.33.4 | Model download | Downloading model weights |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| CUDA 12.1 | CUDA 12.4 | 12.4 works but 12.1 matches spconv-cu120 minor version better |
| Official ReconViaGen | Stable-X implementation | Only available option - official code not released |
| PyTorch3D 0.7.5 (cu118) | PyTorch3D 0.7.8 (third-party wheel) | May need to build from source or skip if not essential |

**Installation:**
```bash
# In Dockerfile, use official PyTorch image or install from wheels
pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121

# Sparse convolutions (CUDA 12 compatible)
pip install spconv-cu120==2.3.6

# xformers - pinned version for compatibility
pip install xformers==0.0.27.post2

# flash-attn - use pre-built wheel to avoid compilation
pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.0.post2/flash_attn-2.7.0.post2+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl

# nvdiffrast - from git with no-build-isolation
pip install --no-build-isolation git+https://github.com/NVlabs/nvdiffrast/

# tiny-cuda-nn - required by nvdiffrec
pip install git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch
```

## Architecture Patterns

### Recommended Project Structure
```
app/
├── models/
│   ├── base.py              # Existing abstract base
│   ├── reconviagen.py       # Replace STUB with real implementation
│   ├── nvdiffrec.py         # Replace STUB with real implementation
│   └── trellis/             # NEW: TRELLIS pipeline components
│       ├── __init__.py
│       ├── pipeline.py      # TrellisVGGTTo3DPipeline wrapper
│       └── postprocessing.py
├── services/
│   └── camera_estimation.py # NEW: Camera pose estimation for nvdiffrec
weights/
├── reconviagen/
│   ├── trellis-vggt-v0-2/   # From Stable-X/trellis-vggt-v0-2
│   └── mast3r/              # From naver/MASt3R_ViTLarge_...
└── nvdiffrec/
    └── (no pre-trained weights - optimization from scratch)
```

### Pattern 1: TRELLIS Pipeline Integration
**What:** Load pre-trained TRELLIS-VGGT model and wrap for multi-view reconstruction
**When to use:** ReconViaGen inference
**Example:**
```python
# Source: https://huggingface.co/spaces/Stable-X/ReconViaGen/blob/main/app.py
from trellis.pipelines import TrellisVGGTTo3DPipeline

class ReconViaGenModel(BaseReconstructionModel):
    def load_weights(self) -> None:
        self._pipeline = TrellisVGGTTo3DPipeline.from_pretrained(
            "Stable-X/trellis-vggt-v0-2"
        )
        self._pipeline.cuda()

    def inference(self, input_dir: Path, output_dir: Path) -> dict:
        images = self._load_images(input_dir)
        outputs, _, _ = self._pipeline.run(
            image=images,
            seed=42,
            formats=["gaussian", "mesh"],
            preprocess_image=False,
            sparse_structure_sampler_params={"steps": 30, "cfg_strength": 7.5},
            slat_sampler_params={"steps": 12, "cfg_strength": 3.0},
        )
        mesh = outputs['mesh'][0]
        # Export mesh to OBJ/PLY
        return {'status': 'success', 'mesh_path': ...}
```

### Pattern 2: nvdiffrec Optimization Loop
**What:** Run iterative optimization to reconstruct mesh from images
**When to use:** nvdiffrec inference (optimization-based, not feedforward)
**Example:**
```python
# Source: https://github.com/NVlabs/nvdiffrec/blob/main/train.py
import nvdiffrast.torch as dr

class NvdiffrecModel(BaseReconstructionModel):
    def __init__(self, iterations=1000):
        self._glctx = dr.RasterizeGLContext()
        self._iterations = iterations

    def inference(self, input_dir: Path, output_dir: Path) -> dict:
        # Load NeRF-format dataset
        dataset = DatasetNERF(
            os.path.join(input_dir, 'transforms_train.json'),
            FLAGS
        )

        # Initialize geometry and materials
        geometry = DMTetGeometry(...)
        materials = create_trainable_env_rnd(...)

        # Optimization loop
        optimizer = torch.optim.Adam([...], lr=0.01)
        for i in range(self._iterations):
            batch = dataset.collate()
            loss = self._render_and_compute_loss(geometry, materials, batch)
            loss.backward()
            optimizer.step()

            self.report_progress(30 + int(50 * i / self._iterations),
                                f"Optimizing ({i}/{self._iterations})")

        # Extract final mesh
        mesh = geometry.getMesh(materials)
        return {'status': 'success', 'mesh_path': ...}
```

### Pattern 3: NeRF Dataset Format for nvdiffrec
**What:** Prepare input images in NeRF format with camera poses
**When to use:** Converting multi-view input to nvdiffrec-compatible format
**Example:**
```json
// transforms_train.json format
{
    "camera_angle_x": 0.6911,
    "frames": [
        {
            "file_path": "./views/view_00",
            "transform_matrix": [
                [1.0, 0.0, 0.0, 0.0],
                [0.0, 1.0, 0.0, 0.0],
                [0.0, 0.0, 1.0, 2.5],
                [0.0, 0.0, 0.0, 1.0]
            ]
        }
    ]
}
```

### Anti-Patterns to Avoid
- **Mixing CUDA major versions:** Don't use CUDA 11.8 libraries with CUDA 12.x PyTorch - causes symbol errors
- **Building flash-attn from source:** Takes 1+ hours and often fails - use pre-built wheels
- **Skipping --no-build-isolation:** nvdiffrast and tiny-cuda-nn need this flag to find PyTorch
- **Using xformers latest:** Version must match PyTorch exactly - pin to 0.0.27.post2 for PyTorch 2.4

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Camera pose estimation | Custom COLMAP integration | MASt3R model (bundled with ReconViaGen) | Trained for metric 3D, handles sparse views |
| Background removal | Manual segmentation | rembg / BiRefNet (bundled) | Pre-trained, handles complex edges |
| Mesh simplification | Custom decimation | trimesh.simplify_quadric_decimation | Battle-tested, preserves topology |
| GLB/GLTF export | Manual format writing | trimesh.exchange.gltf | Handles materials, textures, compression |
| Differentiable rendering | Custom CUDA kernels | nvdiffrast | NVIDIA-optimized, extensively tested |

**Key insight:** The Stable-X/ReconViaGen implementation bundles camera estimation (MASt3R/VGGT) and background removal (BiRefNet) into a single pipeline. Using this saves weeks of integration work.

## Common Pitfalls

### Pitfall 1: CUDA Version Mismatch
**What goes wrong:** Undefined symbol errors at runtime, import failures
**Why it happens:** PyTorch wheels, spconv, nvdiffrast compiled against different CUDA versions
**How to avoid:**
- Use consistent CUDA 12.1 throughout
- Install PyTorch FIRST with --index-url
- Pin all CUDA-dependent packages
**Warning signs:** `undefined symbol`, `CUDA driver version is insufficient`

### Pitfall 2: PyTorch3D CUDA 12 Compatibility
**What goes wrong:** No official PyTorch3D wheels for CUDA 12.x
**Why it happens:** Facebook only ships wheels for CUDA 11.x
**How to avoid:**
- Option A: Use third-party wheels from miropsota.github.io
- Option B: Build from source in Dockerfile
- Option C: Replace PyTorch3D usage with trimesh + nvdiffrast
**Warning signs:** `pip install pytorch3d` pulls wrong version or fails

### Pitfall 3: flash-attn Build Failures
**What goes wrong:** Compilation takes hours then fails with OOM or nvcc errors
**Why it happens:** flash-attn compiles massive CUDA kernels
**How to avoid:**
- Use pre-built wheel from GitHub releases
- URL: `https://github.com/Dao-AILab/flash-attention/releases`
- Match Python version (cp310), CUDA (cu12), and PyTorch (torch2.4)
**Warning signs:** Build taking >30 minutes, memory exhaustion

### Pitfall 4: spconv NumPy 2.0 Incompatibility
**What goes wrong:** SIGFPE errors, segfaults in sparse convolution operations
**Why it happens:** spconv compiled against NumPy 1.x, NumPy 2.0 breaks ABI
**How to avoid:**
- Pin `numpy<2` in requirements.txt
- Install numpy before spconv
**Warning signs:** Floating point exceptions, mysterious crashes

### Pitfall 5: nvdiffrec Dataset Format
**What goes wrong:** nvdiffrec fails to load images, wrong camera matrices
**Why it happens:** Expects NeRF synthetic format with specific JSON structure
**How to avoid:**
- Generate `transforms_train.json` with camera poses
- Images must have alpha channel for masking
- Camera matrices are 4x4 in OpenGL convention
**Warning signs:** "transforms_train.json not found", incorrect reconstructions

### Pitfall 6: Hugging Face Model Download in Docker
**What goes wrong:** Model download fails during build, or downloads at runtime
**Why it happens:** HF_TOKEN not set, or models not cached properly
**How to avoid:**
- Download models in Dockerfile with explicit HF_HOME
- Cache to persistent volume
- Use `huggingface-cli download` for explicit control
**Warning signs:** RuntimeError during first inference, large runtime downloads

## Code Examples

Verified patterns from official sources:

### Dockerfile Base Image Upgrade
```dockerfile
# Source: PyTorch Docker Hub + requirements analysis
# Option 1: Use official PyTorch image
FROM pytorch/pytorch:2.4.1-cuda12.1-cudnn9-devel

# Option 2: Build from nvidia/cuda base (more control)
FROM nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04

# Install Python 3.10
RUN apt-get update && apt-get install -y \
    python3.10 python3.10-dev python3-pip \
    git build-essential ninja-build \
    && rm -rf /var/lib/apt/lists/*

# Install PyTorch with CUDA 12.1
RUN pip install --no-cache-dir \
    torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 \
    --index-url https://download.pytorch.org/whl/cu121
```

### TRELLIS Pipeline Inference
```python
# Source: https://huggingface.co/spaces/Stable-X/ReconViaGen/blob/main/app.py
import os
os.environ['SPCONV_ALGO'] = 'native'  # Required for spconv

from trellis.pipelines import TrellisVGGTTo3DPipeline
from trellis.utils import render_utils, postprocessing_utils

# Load pipeline
pipeline = TrellisVGGTTo3DPipeline.from_pretrained("Stable-X/trellis-vggt-v0-2")
pipeline.cuda()

# Run inference
outputs, _, _ = pipeline.run(
    image=images,  # List of PIL Images
    seed=42,
    formats=["gaussian", "mesh"],
    preprocess_image=False,
    sparse_structure_sampler_params={"steps": 30, "cfg_strength": 7.5},
    slat_sampler_params={"steps": 12, "cfg_strength": 3.0},
    mode="multidiffusion",  # or "stochastic"
)

# Export mesh
gs = outputs['gaussian'][0]
mesh = outputs['mesh'][0]
glb = postprocessing_utils.to_glb(gs, mesh, simplify=0.95, texture_size=1024)
glb.export("output.glb")
```

### nvdiffrec Configuration JSON
```json
// Source: https://github.com/NVlabs/nvdiffrec
{
    "ref_mesh": "data/custom_dataset",
    "random_textures": true,
    "iter": 1000,
    "save_interval": 100,
    "texture_res": [1024, 1024],
    "train_res": [512, 512],
    "batch": 4,
    "learning_rate": 0.01,
    "dmtet_grid": 64,
    "mesh_scale": 2.1,
    "laplace_scale": 10000.0,
    "display": null,
    "background": "white",
    "out_dir": "out/custom"
}
```

### Model Weight Download Script
```python
# Download TRELLIS-VGGT weights during Docker build
from huggingface_hub import snapshot_download

# Download main model
snapshot_download(
    "Stable-X/trellis-vggt-v0-2",
    local_dir="/app/weights/reconviagen/trellis-vggt",
    local_dir_use_symlinks=False
)

# Download MASt3R for camera estimation
snapshot_download(
    "naver/MASt3R_ViTLarge_BaseDecoder_512_catmlpdpt_metric",
    local_dir="/app/weights/reconviagen/mast3r",
    local_dir_use_symlinks=False
)
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| CUDA 11.8 + PyTorch 2.1 | CUDA 12.1 + PyTorch 2.4 | 2024 | Better GPU support, flash attention native |
| xformers only | flash-attn primary | 2024 | 2-3x faster attention, less memory |
| COLMAP for poses | MASt3R/VGGT | 2025 | End-to-end differentiable, sparse view support |
| DMTet only | FlexiCubes option | 2024 | Better topology for complex shapes |

**Deprecated/outdated:**
- **PyTorch3D official wheels for CUDA 12:** Not available - use third-party or build from source
- **xformers for V100:** flash-attn not supported on V100, use xformers as fallback
- **spconv < 2.3.6:** Earlier versions have CUDA 12 compatibility issues

## Open Questions

Things that couldn't be fully resolved:

1. **ReconViaGen Official Code Release**
   - What we know: GAP-LAB says "stuck in company review", Stable-X has working implementation
   - What's unclear: Will official code ever be released? Is Stable-X implementation authorized?
   - Recommendation: Use Stable-X implementation - it's the only working option

2. **PyTorch3D Requirement**
   - What we know: Current STUB uses PyTorch3D for mesh operations
   - What's unclear: Is PyTorch3D strictly necessary or can trimesh + nvdiffrast replace it?
   - Recommendation: Try replacing PyTorch3D with trimesh; build from source as fallback

3. **nvdiffrec Camera Pose Input**
   - What we know: nvdiffrec expects NeRF-format transforms_train.json with camera poses
   - What's unclear: How to generate accurate poses from just 6 images without COLMAP?
   - Recommendation: Use MASt3R (bundled with ReconViaGen) for pose estimation, or assume fixed canonical poses

4. **Model Weight Size**
   - What we know: TRELLIS-VGGT models are large (~2-4GB), MASt3R is ~2.7GB
   - What's unclear: Will all weights fit in model-weights volume? Docker image size impact?
   - Recommendation: Download weights at runtime first, then optimize Docker image later

## Sources

### Primary (HIGH confidence)
- [PyTorch Previous Versions](https://pytorch.org/get-started/previous-versions/) - CUDA 12.1/12.4 pip commands
- [nvdiffrec GitHub](https://github.com/NVlabs/nvdiffrec) - Configuration, dataset format, installation
- [TRELLIS GitHub](https://github.com/microsoft/TRELLIS) - Dependencies, setup script, inference patterns
- [Stable-X/ReconViaGen HF Space](https://huggingface.co/spaces/Stable-X/ReconViaGen) - Working implementation, requirements.txt

### Secondary (MEDIUM confidence)
- [spconv-cu120 PyPI](https://pypi.org/project/spconv-cu120/) - Version 2.3.6, Python 3.10 support
- [flash-attn Releases](https://github.com/Dao-AILab/flash-attention/releases) - Pre-built wheels
- [PyTorch3D Discussion #1752](https://github.com/facebookresearch/pytorch3d/discussions/1752) - Third-party CUDA 12 wheels
- [NVIDIA CUDA Compatibility Docs](https://docs.nvidia.com/deploy/cuda-compatibility/) - Minor version compatibility

### Tertiary (LOW confidence)
- [estheryang11/ReconViaGen](https://github.com/estheryang11/ReconViaGen) - Unofficial implementation, may be outdated
- WebSearch results for xformers PyTorch 2.4 compatibility - conflicting information about versions

## Metadata

**Confidence breakdown:**
- Standard stack: MEDIUM - PyTorch/CUDA well-documented, but ReconViaGen dependencies based on Stable-X implementation
- Architecture: MEDIUM - nvdiffrec patterns clear, TRELLIS integration based on HF Space code
- Pitfalls: HIGH - Multiple verified sources for CUDA/wheel compatibility issues

**Research date:** 2026-01-31
**Valid until:** 2026-02-28 (30 days - TRELLIS/ReconViaGen ecosystem evolving rapidly)

---

## Key Upgrade Path Summary

### Phase 3.1 Execution Order

1. **Upgrade Dockerfile base image:** nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04
2. **Install PyTorch 2.4.1+cu121 FIRST** (before any other packages)
3. **Pin numpy<2** for spconv compatibility
4. **Install spconv-cu120, xformers, flash-attn** using exact versions above
5. **Install nvdiffrast and tiny-cuda-nn** with --no-build-isolation
6. **Clone/integrate TRELLIS code** from Stable-X implementation
7. **Download model weights** (TRELLIS-VGGT, MASt3R)
8. **Replace ReconViaGen STUB** with TrellisVGGTTo3DPipeline wrapper
9. **Replace nvdiffrec STUB** with optimization loop implementation
10. **Add camera pose estimation** for nvdiffrec input format
11. **Run existing tests** to verify no regressions
