# Phase 3.1: CUDA 12 Upgrade & Real Model Integration - Research

**Researched:** 2026-01-31 (UPDATED)
**Domain:** CUDA/PyTorch ecosystem upgrade, 3D reconstruction model integration
**Confidence:** HIGH (estheryang11/ReconViaGen verified, Stable-X requirements confirmed, nvdiffrec well-documented)

## Summary

This phase requires upgrading from CUDA 11.8 + PyTorch 2.1 to CUDA 12.1 + PyTorch 2.4, then replacing STUB implementations with real ReconViaGen and nvdiffrec models. Key findings:

1. **Use estheryang11/ReconViaGen** - An unofficial PyTorch implementation that uses the TRELLIS-VGGT architecture. Entry point is `app_refine.py` with optimized camera registration. The implementation includes bundled nvdiffrast extensions and TRELLIS pipeline code.

2. **Dependencies are well-documented** - The Stable-X/ReconViaGen HuggingFace Space has a complete `requirements.txt` that the estheryang11 implementation shares. Key packages: PyTorch 2.4.0, spconv-cu120 2.3.6, xformers 0.0.27.post2, flash-attn 2.7.0.post2.

3. **VGGT for camera pose estimation** - Facebook Research's VGGT (CVPR 2025 Best Paper) is integrated into the TRELLIS-VGGT pipeline for accurate camera pose estimation from sparse views. This eliminates the need for COLMAP or MASt3R as separate dependencies.

4. **nvdiffrec remains optimization-based** - nvdiffrec still uses iterative optimization (not feedforward) and requires NeRF-format input with camera poses, which can be provided by the ReconViaGen/VGGT pipeline.

**Primary recommendation:** Clone estheryang11/ReconViaGen with `--recursive` flag, use Stable-X/trellis-vggt-v0-2 model weights, and integrate TrellisVGGTTo3DPipeline into the existing model wrapper interface.

## Standard Stack

The established libraries/tools for this domain:

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| PyTorch | 2.4.0+cu121 | Deep learning framework | Required by estheryang11/ReconViaGen |
| torchvision | 0.19.0 | Image processing | Matches PyTorch 2.4.0 |
| CUDA Toolkit | 12.1 | GPU compute | spconv-cu120 compatible, PyTorch wheels available |
| spconv-cu120 | 2.3.6 | Sparse convolutions | Required for TRELLIS sparse structure generation |
| xformers | 0.0.27.post2 | Memory-efficient attention | Pinned version for PyTorch 2.4 compatibility |
| flash-attn | 2.7.0.post2 | Fast attention | Pre-built wheel for cu12+torch2.4 |
| nvdiffrast | 0.3.3 | Differentiable rasterization | Pre-built wheel from TRELLIS HF Space |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| kornia | 0.8.0 | Computer vision ops | Image preprocessing |
| trimesh | 4.5.3 | Mesh I/O and processing | Mesh export/validation |
| transformers | 4.46.3 | Vision transformers | VGGT model backbone |
| timm | 1.0.23 | Image models | DINO backbone for VGGT |
| einops | 0.8.1 | Tensor operations | Required by attention layers |
| huggingface_hub | 0.33.4 | Model download | Downloading model weights |
| rembg | 2.0.60 | Background removal | Image preprocessing |
| xatlas | 0.0.9 | UV unwrapping | Mesh texture mapping |
| pyvista | 0.44.2 | 3D visualization | Mesh processing |
| pymeshfix | 0.17.0 | Mesh repair | Fix non-manifold meshes |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| CUDA 12.1 | CUDA 12.4 | 12.4 works but spconv-cu120 tested with 12.1 |
| Stable-X/ReconViaGen | estheryang11/ReconViaGen | User-specified choice, includes app_refine.py improvements |
| COLMAP for poses | VGGT (bundled) | VGGT is faster, end-to-end differentiable |

**Installation:**
```bash
# Clone estheryang11/ReconViaGen with submodules
git clone --recursive https://github.com/estheryang11/ReconViaGen.git

# In Dockerfile, install PyTorch FIRST
pip install torch==2.4.0 torchvision==0.19.0 --index-url https://download.pytorch.org/whl/cu121

# Install from requirements.txt (adapted from Stable-X)
pip install kornia==0.8.0 pillow==10.4.0 imageio==2.36.1 imageio-ffmpeg==0.5.1
pip install opencv-python-headless==4.10.0.84 rembg==2.0.60
pip install scipy==1.14.1 tqdm==4.67.1 easydict==1.13 einops==0.8.1
pip install trimesh==4.5.3 xatlas==0.0.9 pyvista==0.44.2 pymeshfix==0.17.0 igraph==0.11.8
pip install transformers==4.46.3 timm==1.0.23 xformers==0.0.27.post2 spconv-cu120==2.3.6
pip install huggingface_hub==0.33.4 lpips==0.1.4

# Install from pre-built wheels (critical for build time)
pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.0.post2/flash_attn-2.7.0.post2+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
pip install https://huggingface.co/spaces/JeffreyXiang/TRELLIS/resolve/main/wheels/diff_gaussian_rasterization-0.0.0-cp310-cp310-linux_x86_64.whl
pip install https://huggingface.co/spaces/JeffreyXiang/TRELLIS/resolve/main/wheels/nvdiffrast-0.3.3-cp310-cp310-linux_x86_64.whl

# Install utils3d from git
pip install git+https://github.com/EasternJournalist/utils3d.git@9a4eb15e4021b67b12c460c7057d642626897ec8

# nvdiffrec dependencies (for later integration)
pip install --no-build-isolation git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch
```

## Architecture Patterns

### Recommended Project Structure
```
app/
├── models/
│   ├── base.py              # Existing abstract base (unchanged)
│   ├── reconviagen.py       # Replace STUB with TrellisVGGTTo3DPipeline
│   ├── nvdiffrec.py         # Replace STUB with real implementation
│   └── trellis/             # NEW: Copy from estheryang11/ReconViaGen/trellis
│       ├── __init__.py
│       ├── pipelines/       # TrellisVGGTTo3DPipeline
│       ├── models/          # SLAT models
│       ├── representations/ # Gaussian, Mesh output types
│       └── utils/           # render_utils, postprocessing_utils
weights/
├── reconviagen/
│   └── trellis-vggt-v0-2/   # From Stable-X/trellis-vggt-v0-2
└── nvdiffrec/
    └── (no pre-trained weights - optimization from scratch)
```

### Pattern 1: TrellisVGGTTo3DPipeline Integration
**What:** Load pre-trained TRELLIS-VGGT model and wrap for multi-view reconstruction
**When to use:** ReconViaGen inference
**Example:**
```python
# Source: https://huggingface.co/spaces/Stable-X/ReconViaGen/blob/main/app.py
import os
os.environ['SPCONV_ALGO'] = 'native'  # Required for spconv

from trellis.pipelines import TrellisVGGTTo3DPipeline
from trellis.utils import postprocessing_utils

class ReconViaGenModel(BaseReconstructionModel):
    model_name = "reconviagen"

    def load_weights(self) -> None:
        self.report_progress(10, "Loading TRELLIS-VGGT pipeline")
        self._pipeline = TrellisVGGTTo3DPipeline.from_pretrained(
            "Stable-X/trellis-vggt-v0-2"
        )
        self._pipeline.cuda()
        self.report_progress(15, "Model loaded")

    def inference(self, input_dir: Path, output_dir: Path) -> dict:
        self.report_progress(20, "Loading input images")
        images = self._load_images(input_dir / "views")

        self.report_progress(30, "Running reconstruction")
        outputs, _, _ = self._pipeline.run(
            image=images,
            seed=42,
            formats=["gaussian", "mesh"],
            preprocess_image=False,
            sparse_structure_sampler_params={
                "steps": 30,
                "cfg_strength": 7.5,
            },
            slat_sampler_params={
                "steps": 12,
                "cfg_strength": 3.0,
            },
            mode="multidiffusion",
        )

        self.report_progress(70, "Exporting mesh")
        gs = outputs['gaussian'][0]
        mesh = outputs['mesh'][0]

        # Export to GLB with texture
        glb = postprocessing_utils.to_glb(
            gs, mesh,
            simplify=0.95,
            texture_size=1024
        )
        glb_path = output_dir / "mesh.glb"
        glb.export(str(glb_path))

        return {
            'status': 'success',
            'mesh_path': str(glb_path),
            'format': 'glb'
        }
```

### Pattern 2: Input Image Loading
**What:** Load multiple view images for pipeline input
**When to use:** Preprocessing step before inference
**Example:**
```python
from PIL import Image

def _load_images(self, views_dir: Path) -> list:
    """Load view images as PIL Images for TRELLIS pipeline."""
    view_files = sorted(views_dir.glob("view_*.png"))
    images = []
    for f in view_files:
        img = Image.open(f).convert("RGB")
        # Resize to 512px height maintaining aspect ratio
        if img.height != 512:
            ratio = 512 / img.height
            new_size = (int(img.width * ratio), 512)
            img = img.resize(new_size, Image.LANCZOS)
        images.append(img)
    return images
```

### Pattern 3: Pipeline Parameters Reference
**What:** Configurable parameters for TrellisVGGTTo3DPipeline.run()
**When to use:** Tuning quality vs speed tradeoffs
**Reference:**
```python
# Source: https://huggingface.co/spaces/Stable-X/ReconViaGen/blob/main/app.py
{
    # General
    "seed": 0,  # Range: 0 to 2^31-1
    "formats": ["gaussian", "mesh"],  # Output formats

    # Stage 1: Sparse Structure Sampling
    "sparse_structure_sampler_params": {
        "steps": 30,       # Range: 1-50, default 30
        "cfg_strength": 7.5,  # Range: 0.0-10.0, default 7.5
    },

    # Stage 2: Structured Latent Sampling
    "slat_sampler_params": {
        "steps": 12,       # Range: 1-50, default 12
        "cfg_strength": 3.0,  # Range: 0.0-10.0, default 3.0
    },

    # Multi-image algorithm
    "mode": "multidiffusion",  # or "stochastic"
    "preprocess_image": False,  # Set True for auto background removal
}
```

### Pattern 4: GLB Export with Texture
**What:** Convert Gaussian + Mesh output to textured GLB file
**When to use:** Final output export
**Example:**
```python
from trellis.utils import postprocessing_utils

# Get outputs from pipeline
gs = outputs['gaussian'][0]  # 3D Gaussian representation
mesh = outputs['mesh'][0]    # Mesh representation

# Export to GLB with texture
glb = postprocessing_utils.to_glb(
    gs,
    mesh,
    simplify=0.95,      # Range: 0.9-0.98, higher = more simplification
    texture_size=1024,  # Range: 512-2048
)
glb.export("output.glb")
```

### Anti-Patterns to Avoid
- **Missing SPCONV_ALGO env var:** Must set `os.environ['SPCONV_ALGO'] = 'native'` before importing trellis
- **Building wheels from source:** Use pre-built wheels for flash-attn, nvdiffrast, diff_gaussian_rasterization
- **Mixing CUDA major versions:** All packages must use CUDA 12.x (not mixing with 11.x)
- **Using latest xformers:** Version must match PyTorch exactly - pin to 0.0.27.post2 for PyTorch 2.4

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Camera pose estimation | Custom COLMAP integration | VGGT (bundled in TrellisVGGT pipeline) | Trained end-to-end, handles sparse views in <1 sec |
| Background removal | Manual segmentation | rembg 2.0.60 (in requirements) | Pre-trained, handles complex edges |
| Mesh simplification | Custom decimation | postprocessing_utils.to_glb(simplify=0.95) | Integrated in TRELLIS output pipeline |
| GLB/GLTF export | Manual format writing | trimesh via to_glb() | Handles materials, textures, compression |
| Gaussian to mesh | Custom marching cubes | TRELLIS mesh decoder | Trained jointly with gaussian encoder |
| UV unwrapping | Custom parameterization | xatlas 0.0.9 | Industry-standard, handles complex topology |
| Sparse convolutions | Dense convolution fallback | spconv-cu120 | Orders of magnitude faster for SLAT |

**Key insight:** The estheryang11/ReconViaGen bundles the entire TRELLIS-VGGT pipeline including camera estimation via VGGT, which outputs camera intrinsics and extrinsics directly. No separate pose estimation step needed.

## Common Pitfalls

### Pitfall 1: Missing SPCONV_ALGO Environment Variable
**What goes wrong:** spconv crashes with cryptic CUDA errors or hangs indefinitely
**Why it happens:** spconv has multiple algorithm backends, 'native' is required for TRELLIS
**How to avoid:**
```python
import os
os.environ['SPCONV_ALGO'] = 'native'
# Must be set BEFORE any trellis imports
```
**Warning signs:** Hang during model loading, segfault in spconv

### Pitfall 2: CUDA Version Mismatch
**What goes wrong:** Undefined symbol errors at runtime, import failures
**Why it happens:** PyTorch wheels, spconv, nvdiffrast compiled against different CUDA versions
**How to avoid:**
- Use consistent CUDA 12.1 throughout
- Install PyTorch FIRST with --index-url
- Use pre-built wheels from HF/GitHub releases
**Warning signs:** `undefined symbol`, `CUDA driver version is insufficient`

### Pitfall 3: Building flash-attn from Source
**What goes wrong:** Compilation takes 1+ hours then fails with OOM or nvcc errors
**Why it happens:** flash-attn compiles massive CUDA kernels
**How to avoid:**
- Use pre-built wheel from GitHub releases:
  ```
  https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.0.post2/flash_attn-2.7.0.post2+cu12torch2.4cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
  ```
- Match Python version (cp310), CUDA (cu12), and PyTorch (torch2.4)
**Warning signs:** Build taking >30 minutes, memory exhaustion

### Pitfall 4: spconv NumPy 2.0 Incompatibility
**What goes wrong:** SIGFPE errors, segfaults in sparse convolution operations
**Why it happens:** spconv compiled against NumPy 1.x, NumPy 2.0 breaks ABI
**How to avoid:**
- Pin `numpy<2` in requirements
- Install numpy before spconv
**Warning signs:** Floating point exceptions, mysterious crashes

### Pitfall 5: HuggingFace Model Download in Docker
**What goes wrong:** Model download fails during build, or downloads at runtime causing slow first inference
**Why it happens:** HF_TOKEN not set, or models not cached properly
**How to avoid:**
- Download models in Dockerfile with explicit HF_HOME:
  ```dockerfile
  ENV HF_HOME=/app/weights/huggingface
  RUN python -c "from huggingface_hub import snapshot_download; snapshot_download('Stable-X/trellis-vggt-v0-2', local_dir='/app/weights/reconviagen/trellis-vggt-v0-2')"
  ```
- Or download at runtime to persistent volume on first run
**Warning signs:** RuntimeError during first inference, large runtime downloads

### Pitfall 6: Wrong Image Size for Pipeline
**What goes wrong:** CUDA OOM or poor reconstruction quality
**Why it happens:** TRELLIS expects 512px height images
**How to avoid:**
- Resize input images to 512px height maintaining aspect ratio
- Or set `preprocess_image=True` in pipeline.run() for auto-resize
**Warning signs:** OOM errors, blurry/wrong reconstructions

## Code Examples

Verified patterns from official sources:

### Dockerfile Base Image Upgrade
```dockerfile
# Source: Requirements analysis from Stable-X/ReconViaGen
FROM nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04

# Install Python 3.10
RUN apt-get update && apt-get install -y \
    python3.10 python3.10-dev python3-pip \
    git build-essential ninja-build \
    libgl1-mesa-glx libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/*

# Link python3.10 as default
RUN ln -sf /usr/bin/python3.10 /usr/bin/python && \
    ln -sf /usr/bin/pip3 /usr/bin/pip

# Install PyTorch with CUDA 12.1 FIRST
RUN pip install --no-cache-dir \
    torch==2.4.0 torchvision==0.19.0 \
    --index-url https://download.pytorch.org/whl/cu121

# Pin numpy<2 for spconv compatibility
RUN pip install --no-cache-dir "numpy<2"
```

### Full ReconViaGen Model Implementation
```python
# Source: Based on https://huggingface.co/spaces/Stable-X/ReconViaGen/blob/main/app.py
import os
os.environ['SPCONV_ALGO'] = 'native'

import logging
from pathlib import Path
from typing import Optional
import torch
from PIL import Image

from app.models.base import BaseReconstructionModel
from app.services.vram_manager import cleanup_gpu_memory, check_vram_available

# Lazy import to ensure env var is set first
_pipeline = None

logger = logging.getLogger(__name__)

WEIGHTS_PATH = Path("/app/weights/reconviagen/trellis-vggt-v0-2")
REQUIRED_VRAM_GB = 16.0  # Based on TRELLIS requirements

class ReconViaGenModel(BaseReconstructionModel):
    model_name = "reconviagen"

    def __init__(self, celery_task=None):
        super().__init__(celery_task)
        self._device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    def load_weights(self) -> None:
        self.report_progress(5, "Checking VRAM availability")
        vram_status = check_vram_available(REQUIRED_VRAM_GB)
        if not vram_status['available']:
            raise RuntimeError(
                f"Insufficient VRAM: {vram_status['free_gb']:.1f}GB available, "
                f"{REQUIRED_VRAM_GB}GB required"
            )

        self.report_progress(10, "Loading TRELLIS-VGGT pipeline")
        logger.info(f"Loading TrellisVGGTTo3DPipeline from {WEIGHTS_PATH}")

        from trellis.pipelines import TrellisVGGTTo3DPipeline

        if WEIGHTS_PATH.exists():
            self._model = TrellisVGGTTo3DPipeline.from_pretrained(str(WEIGHTS_PATH))
        else:
            # Fall back to HuggingFace download
            self._model = TrellisVGGTTo3DPipeline.from_pretrained("Stable-X/trellis-vggt-v0-2")

        self._model.cuda()
        logger.info("TrellisVGGTTo3DPipeline loaded successfully")
        self.report_progress(15, "Model loaded")

    def _load_images(self, views_dir: Path) -> list:
        """Load view images as PIL Images."""
        view_files = sorted(views_dir.glob("view_*.png"))
        images = []
        for f in view_files:
            img = Image.open(f).convert("RGB")
            # Resize to 512px height maintaining aspect ratio
            if img.height != 512:
                ratio = 512 / img.height
                new_size = (int(img.width * ratio), 512)
                img = img.resize(new_size, Image.LANCZOS)
            images.append(img)
        logger.info(f"Loaded {len(images)} images from {views_dir}")
        return images

    def inference(self, input_dir: Path, output_dir: Path) -> dict:
        from trellis.utils import postprocessing_utils

        input_dir = Path(input_dir)
        output_dir = Path(output_dir)

        try:
            self.report_progress(20, "Loading input images")
            views_dir = input_dir / "views"

            if not views_dir.exists():
                return {'status': 'failed', 'error': "Input directory missing views/ subdirectory"}

            images = self._load_images(views_dir)
            if len(images) == 0:
                return {'status': 'failed', 'error': "No view images found"}

            self.report_progress(30, "Running 3D reconstruction")
            logger.info(f"Running inference with {len(images)} images")

            outputs, _, _ = self._model.run(
                image=images,
                seed=42,
                formats=["gaussian", "mesh"],
                preprocess_image=False,
                sparse_structure_sampler_params={
                    "steps": 30,
                    "cfg_strength": 7.5,
                },
                slat_sampler_params={
                    "steps": 12,
                    "cfg_strength": 3.0,
                },
                mode="multidiffusion",
            )

            self.report_progress(70, "Exporting mesh")
            output_dir.mkdir(parents=True, exist_ok=True)

            gs = outputs['gaussian'][0]
            mesh = outputs['mesh'][0]

            # Export to GLB with texture
            glb = postprocessing_utils.to_glb(gs, mesh, simplify=0.95, texture_size=1024)
            glb_path = output_dir / "mesh.glb"
            glb.export(str(glb_path))

            # Also save PLY for Gaussian splatting
            ply_path = output_dir / "gaussian.ply"
            gs.save_ply(str(ply_path))

            self.report_progress(90, "Validation complete")

            return {
                'status': 'success',
                'mesh_path': str(glb_path),
                'ply_path': str(ply_path),
            }

        except torch.cuda.OutOfMemoryError as e:
            logger.error(f"CUDA OOM during inference: {e}")
            cleanup_gpu_memory()
            return {'status': 'failed', 'error': "Out of GPU memory"}
        except Exception as e:
            logger.error(f"Inference failed: {e}", exc_info=True)
            return {'status': 'failed', 'error': str(e)}
```

### Model Weight Download Script
```python
# Download TRELLIS-VGGT weights during Docker build
from huggingface_hub import snapshot_download

# Download main model
snapshot_download(
    "Stable-X/trellis-vggt-v0-2",
    local_dir="/app/weights/reconviagen/trellis-vggt-v0-2",
    local_dir_use_symlinks=False
)
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| CUDA 11.8 + PyTorch 2.1 | CUDA 12.1 + PyTorch 2.4 | 2024 | Better GPU support, flash attention native |
| COLMAP for camera poses | VGGT (bundled) | 2025 | 10x faster, end-to-end differentiable, CVPR Best Paper |
| MASt3R for poses | VGGT (bundled) | 2025 | VGGT outperforms MASt3R (85.3 vs 76.4 AUC@30) |
| Stable-X/TRELLIS | estheryang11/ReconViaGen | 2025 | User-specified, includes app_refine.py improvements |
| xformers only | flash-attn primary | 2024 | 2-3x faster attention, less memory |

**Deprecated/outdated:**
- **Official ReconViaGen code:** Still not released (stuck in company review) - use estheryang11 unofficial
- **PyTorch3D official wheels for CUDA 12:** Not available - use trimesh + nvdiffrast instead
- **MASt3R for pose estimation:** VGGT is now superior and bundled in TRELLIS-VGGT

## Open Questions

Things that couldn't be fully resolved:

1. **estheryang11 app_refine.py specifics**
   - What we know: README mentions "optimized camera registration" in app_refine.py
   - What's unclear: Exact changes vs app.py, may need to inspect source code
   - Recommendation: Clone repo and compare app_refine.py vs Stable-X app.py

2. **Model Weight Size**
   - What we know: TRELLIS-VGGT-v0-2 models are ~2-4GB
   - What's unclear: Exact total size, Docker image impact
   - Recommendation: Download at runtime to persistent volume on first run

3. **Output Format Compatibility**
   - What we know: Pipeline outputs GLB with texture, existing interface expects OBJ+texture
   - What's unclear: Whether to keep OBJ or switch to GLB
   - Recommendation: GLB is superior (single file, PBR materials), update interface

4. **Depth Input Usage**
   - What we know: Existing interface has depth/ subdirectory, TRELLIS-VGGT uses VGGT for geometry
   - What's unclear: Whether depth maps can improve reconstruction
   - Recommendation: Initially ignore depth input, VGGT estimates geometry from RGB only

## Sources

### Primary (HIGH confidence)
- [estheryang11/ReconViaGen GitHub](https://github.com/estheryang11/ReconViaGen) - Unofficial implementation, project structure, README
- [Stable-X/ReconViaGen HF Space](https://huggingface.co/spaces/Stable-X/ReconViaGen) - Complete requirements.txt, app.py implementation
- [Stable-X/trellis-vggt-v0-2 HF Model](https://huggingface.co/Stable-X/trellis-vggt-v0-2) - Model card, usage
- [Microsoft TRELLIS GitHub](https://github.com/microsoft/TRELLIS) - Official TRELLIS documentation, installation
- [Facebook VGGT GitHub](https://github.com/facebookresearch/vggt) - CVPR 2025 Best Paper, camera pose estimation

### Secondary (MEDIUM confidence)
- [flash-attn Releases](https://github.com/Dao-AILab/flash-attention/releases) - Pre-built wheels v2.7.0.post2
- [JeffreyXiang/TRELLIS HF Space](https://huggingface.co/spaces/JeffreyXiang/TRELLIS) - Pre-built nvdiffrast/diff_gaussian_rasterization wheels
- [xformers PyPI](https://pypi.org/project/xformers/) - Version compatibility matrix

### Tertiary (LOW confidence)
- [GAP-LAB-CUHK-SZ/ReconViaGen](https://github.com/GAP-LAB-CUHK-SZ/ReconViaGen) - Official repo, but code not released

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - Verified from Stable-X requirements.txt and HF Space
- Architecture: HIGH - Full app.py implementation analyzed from Stable-X
- Pitfalls: HIGH - Multiple verified sources for CUDA/wheel compatibility issues
- Integration: MEDIUM - estheryang11 app_refine.py specifics need source inspection

**Research date:** 2026-01-31 (UPDATED from initial research)
**Valid until:** 2026-02-28 (30 days - TRELLIS/ReconViaGen ecosystem evolving)

---

## Key Upgrade Path Summary

### Phase 3.1 Execution Order (UPDATED)

1. **Upgrade Dockerfile base image:** nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04
2. **Install PyTorch 2.4.0+cu121 FIRST** (before any other packages)
3. **Pin numpy<2** for spconv compatibility
4. **Install dependencies from verified requirements.txt** (see Standard Stack)
5. **Use pre-built wheels** for flash-attn, nvdiffrast, diff_gaussian_rasterization
6. **Clone estheryang11/ReconViaGen** with --recursive flag
7. **Copy trellis/ module** to app/models/trellis/
8. **Download model weights** (Stable-X/trellis-vggt-v0-2)
9. **Replace ReconViaGen STUB** with TrellisVGGTTo3DPipeline wrapper
10. **Update output format** from OBJ to GLB (or support both)
11. **nvdiffrec integration** (separate task, uses VGGT camera poses as input)
12. **Run existing tests** to verify no regressions
