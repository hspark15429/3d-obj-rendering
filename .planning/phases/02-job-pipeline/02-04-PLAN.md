---
phase: 02-job-pipeline
plan: 04
type: execute
wave: 2
depends_on: ["02-01", "02-02", "02-03"]
files_modified:
  - app/api/jobs.py
  - app/main.py
autonomous: false

must_haves:
  truths:
    - "User can POST /jobs with files and receive job_id"
    - "User can GET /jobs/{job_id} and see status with progress"
    - "User can POST /jobs/{job_id}/cancel to request cancellation"
    - "User can POST /jobs/{job_id}/cancel with confirm=true to confirm"
    - "Invalid uploads return 400 with clear error message"
  artifacts:
    - path: "app/api/jobs.py"
      provides: "Job API router"
      exports: ["router"]
    - path: "app/main.py"
      provides: "FastAPI app with job router"
      contains: "include_router"
  key_links:
    - from: "app/api/jobs.py"
      to: "app/tasks/reconstruction.py"
      via: "process_reconstruction.delay"
      pattern: "process_reconstruction\\.delay"
    - from: "app/api/jobs.py"
      to: "app/services/file_handler.py"
      via: "validate_upload_files"
      pattern: "validate_upload_files"
    - from: "app/api/jobs.py"
      to: "app/services/job_manager.py"
      via: "cancellation functions"
      pattern: "(request_cancellation|confirm_cancellation)"
    - from: "app/main.py"
      to: "app/api/jobs.py"
      via: "router inclusion"
      pattern: "include_router.*jobs"
---

<objective>
Create job API endpoints and integrate everything into the FastAPI application.

Purpose: This plan wires together all the components from previous plans into working API endpoints. Users can submit jobs, check status, and cancel jobs through the API.
Output: jobs.py router with POST /jobs, GET /jobs/{job_id}, POST /jobs/{job_id}/cancel endpoints, main.py updated with router.
</objective>

<execution_context>
@/home/devuser/.claude/get-shit-done/workflows/execute-plan.md
@/home/devuser/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-job-pipeline/02-CONTEXT.md
@.planning/phases/02-job-pipeline/02-RESEARCH.md
@.planning/phases/02-job-pipeline/02-01-SUMMARY.md
@.planning/phases/02-job-pipeline/02-02-SUMMARY.md
@.planning/phases/02-job-pipeline/02-03-SUMMARY.md
@app/main.py
@app/api/schemas.py
@app/services/file_handler.py
@app/services/job_manager.py
@app/tasks/reconstruction.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create job API router with all endpoints</name>
  <files>app/api/jobs.py</files>
  <action>
Create app/api/jobs.py with APIRouter:

1. Imports:
   - FastAPI: APIRouter, UploadFile, File, HTTPException, Query
   - nanoid: generate
   - datetime: datetime, timezone
   - From schemas: JobSubmitResponse, JobStatusResponse, CancelRequest, CancelResponse, JobStatus
   - From file_handler: validate_upload_files, save_job_files, FileValidationError
   - From job_manager: request_cancellation, confirm_cancellation, is_job_cancelled, cancel_pending
   - From celery_app: celery_app (for AsyncResult)

2. router = APIRouter(prefix="/jobs", tags=["jobs"])

3. Helper: generate_job_id() -> str
   - Use nanoid.generate(alphabet="0123456789abcdefghijklmnopqrstuvwxyz", size=8)
   - Returns human-friendly 8-char ID like "k3m8xq2p"

4. POST /jobs endpoint:
   @router.post("/", response_model=JobSubmitResponse)
   async def submit_job(
       views: list[UploadFile] = File(..., description="6 multi-view PNG images"),
       depth_renders: list[UploadFile] = File(..., description="6 depth render PNG images"),
       model_type: str = Query("reconviagen", description="Model: reconviagen or nvdiffrec")
   ):
   - Validate model_type in ["reconviagen", "nvdiffrec"], raise 400 if invalid
   - Call validate_upload_files(views, depth_renders) - catch FileValidationError, return 400
   - Generate job_id
   - Call save_job_files(job_id, views, depth_renders)
   - Import and call process_reconstruction.delay(job_id, model_type)
   - Return JobSubmitResponse with job_id, status="queued", created_at=now

5. GET /jobs/{job_id} endpoint:
   @router.get("/{job_id}", response_model=JobStatusResponse)
   async def get_job_status(job_id: str):
   - Get AsyncResult from celery_app.AsyncResult(job_id)
   - Map Celery states to JobStatus:
     - PENDING -> queued
     - STARTED -> processing (progress=0)
     - PROGRESS -> processing (get progress from result.info)
     - SUCCESS -> completed
     - FAILURE -> failed (get error from result.info)
     - REVOKED -> cancelled
   - Check cancel_pending(job_id) - if True and state is PENDING, show status="queued" with note
   - Return JobStatusResponse

6. POST /jobs/{job_id}/cancel endpoint:
   @router.post("/{job_id}/cancel", response_model=CancelResponse)
   async def cancel_job(job_id: str, body: CancelRequest = None):
   - If body is None or body.confirm is False:
     - Call request_cancellation(job_id)
     - Return status="cancel_requested", message="Send confirm=true to confirm cancellation"
   - If body.confirm is True:
     - Call confirm_cancellation(job_id)
     - Return status="cancelled", message="Job cancellation confirmed"

Handle edge cases:
- Job not found: Check if AsyncResult exists, return 404 if truly not found
- Already completed/failed: Cannot cancel, return 400
- Already cancelled: Return current status

Use flat JSON responses per CONTEXT.md decision.
  </action>
  <verify>
python -c "
from app.api.jobs import router
print('Router prefix:', router.prefix)
print('Routes:', [r.path for r in router.routes])
"
  </verify>
  <done>
jobs.py router has 3 routes: POST /, GET /{job_id}, POST /{job_id}/cancel. All handlers implemented with proper imports.
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate router into FastAPI app</name>
  <files>app/main.py</files>
  <action>
Update app/main.py:

1. Add import: from app.api.jobs import router as jobs_router

2. After app = FastAPI(...), add:
   app.include_router(jobs_router)

3. Add exception handler for FileValidationError:
   from app.services.file_handler import FileValidationError

   @app.exception_handler(FileValidationError)
   async def file_validation_handler(request, exc):
       return JSONResponse(
           status_code=400,
           content={"error": str(exc.message), "field": exc.field}
       )

4. Ensure storage directory exists at startup (in lifespan):
   - Add: Path("/app/storage/jobs").mkdir(parents=True, exist_ok=True)
   - Import Path from pathlib

Keep all existing code (GPU validation, health endpoint).
  </action>
  <verify>
python -c "
from app.main import app
print('Routes:', [r.path for r in app.routes])
"
grep -q "include_router" app/main.py && echo "Router included"
  </verify>
  <done>
main.py includes jobs router. App has routes: /health, /jobs, /jobs/{job_id}, /jobs/{job_id}/cancel. FileValidationError handler registered.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 3: End-to-end API verification</name>
  <what-built>
Complete job pipeline API: submit jobs with file upload, check status with progress, cancel jobs with two-step confirmation.
  </what-built>
  <how-to-verify>
1. Rebuild and start services:
   docker-compose down && docker-compose up --build -d
   Wait ~30 seconds for all services

2. Check all services running:
   docker-compose ps
   (Should show api, redis, worker all healthy/running)

3. Create test PNG files (or use existing ones):
   # Create minimal valid PNGs for testing
   mkdir -p /tmp/test_upload
   for i in {0..5}; do
     convert -size 100x100 xc:red /tmp/test_upload/view_$i.png
     convert -size 100x100 xc:gray /tmp/test_upload/depth_$i.png
   done

4. Submit a job:
   curl -X POST http://localhost:8000/jobs \
     -F "views=@/tmp/test_upload/view_0.png" \
     -F "views=@/tmp/test_upload/view_1.png" \
     -F "views=@/tmp/test_upload/view_2.png" \
     -F "views=@/tmp/test_upload/view_3.png" \
     -F "views=@/tmp/test_upload/view_4.png" \
     -F "views=@/tmp/test_upload/view_5.png" \
     -F "depth_renders=@/tmp/test_upload/depth_0.png" \
     -F "depth_renders=@/tmp/test_upload/depth_1.png" \
     -F "depth_renders=@/tmp/test_upload/depth_2.png" \
     -F "depth_renders=@/tmp/test_upload/depth_3.png" \
     -F "depth_renders=@/tmp/test_upload/depth_4.png" \
     -F "depth_renders=@/tmp/test_upload/depth_5.png" \
     -F "model_type=reconviagen"

   Expected: {"job_id": "abc12345", "status": "queued", "created_at": "..."}

5. Check job status (use job_id from step 4):
   curl http://localhost:8000/jobs/{job_id}

   Expected during processing: {"job_id": "...", "status": "processing", "progress": 20, ...}
   Expected after completion: {"job_id": "...", "status": "completed", ...}

6. Test cancellation flow (submit new job, cancel quickly):
   # Submit
   JOB=$(curl -s -X POST http://localhost:8000/jobs ... | jq -r .job_id)

   # Request cancel (step 1)
   curl -X POST http://localhost:8000/jobs/$JOB/cancel
   Expected: {"status": "cancel_requested", "message": "..."}

   # Confirm cancel (step 2)
   curl -X POST http://localhost:8000/jobs/$JOB/cancel \
     -H "Content-Type: application/json" \
     -d '{"confirm": true}'
   Expected: {"status": "cancelled", ...}

7. Test validation errors:
   # Wrong file count
   curl -X POST http://localhost:8000/jobs \
     -F "views=@/tmp/test_upload/view_0.png" \
     -F "depth_renders=@/tmp/test_upload/depth_0.png"
   Expected: 400 error about file count

8. Check API docs:
   Open http://localhost:8000/docs
   Verify /jobs endpoints are documented with correct parameters
  </how-to-verify>
  <resume-signal>Type "approved" if all tests pass, or describe issues encountered</resume-signal>
</task>

</tasks>

<verification>
- POST /jobs accepts 12 files (6 views + 6 depth) and returns job_id
- GET /jobs/{job_id} returns status with progress when processing
- POST /jobs/{job_id}/cancel implements two-step cancellation
- Invalid uploads return 400 with descriptive error
- Worker processes jobs and updates progress
- Cancelled jobs show "cancelled" status
- API docs at /docs show all endpoints
</verification>

<success_criteria>
1. Job submission endpoint accepts multipart upload with 12 PNG files
2. Job status endpoint shows progress percentage during processing
3. Cancellation requires two-step confirmation
4. File validation rejects wrong count, non-PNG, oversized files
5. Worker processes placeholder reconstruction task
6. All endpoints return flat JSON per CONTEXT.md
7. API documentation accessible at /docs
</success_criteria>

<output>
After completion, create `.planning/phases/02-job-pipeline/02-04-SUMMARY.md`
</output>
