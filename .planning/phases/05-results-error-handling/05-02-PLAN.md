---
phase: 05-results-error-handling
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - app/services/result_packager.py
  - app/api/jobs.py
autonomous: true

must_haves:
  truths:
    - "User can download all job outputs as single ZIP by job ID"
    - "ZIP contains mesh files (OBJ, PLY, GLB), textures, all preview images, quality.json"
    - "Download returns 404 for unknown jobs, 409 for incomplete jobs, 410 for expired jobs"
  artifacts:
    - path: "app/services/result_packager.py"
      provides: "ZIP packaging logic"
      contains: "def create_result_zip"
    - path: "app/api/jobs.py"
      provides: "Download endpoint"
      contains: "def download_results"
  key_links:
    - from: "app/api/jobs.py"
      to: "app/services/result_packager.py"
      via: "import create_result_zip"
      pattern: "from app\\.services\\.result_packager import"
    - from: "app/api/jobs.py"
      to: "app/celery_app"
      via: "celery_app.AsyncResult for job state"
      pattern: "celery_app\\.AsyncResult"
---

<objective>
Implement result download functionality for completed jobs.

Purpose: Per API-03 requirement, users must be able to download all job outputs (mesh, textures, previews, quality report) by job ID. Per CONTEXT.md, all outputs packaged in single ZIP file.

Output:
- app/services/result_packager.py with ZIP creation logic
- Updated app/api/jobs.py with GET /{job_id}/download endpoint
</objective>

<execution_context>
@/home/devuser/.claude/get-shit-done/workflows/execute-plan.md
@/home/devuser/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-results-error-handling/05-CONTEXT.md
@.planning/phases/05-results-error-handling/05-RESEARCH.md
@app/api/jobs.py
@app/services/file_handler.py
@app/tasks/reconstruction.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create result packager service</name>
  <files>app/services/result_packager.py</files>
  <action>
Create app/services/result_packager.py with:

1. `create_result_zip(job_id: str, output_dir: Path) -> BytesIO`:
   - Create ZIP in memory using BytesIO + ZipFile(ZIP_DEFLATED, compresslevel=6)
   - Per CONTEXT.md: ZIP contains ALL outputs from each model subdirectory

   ZIP structure (per model directory in output/):
   ```
   {model_name}/
     mesh.obj
     mesh.ply
     mesh.glb
     mesh.mtl (if exists)
     texture.png (mesh.png renamed)
     previews/
       textured_00.png ... textured_05.png
       wireframe_00.png ... wireframe_05.png
     quality.json
   ```

   - Iterate over model directories in output_dir (reconviagen, nvdiffrec)
   - For each model dir, add:
     - mesh.obj, mesh.ply, mesh.glb, mesh.mtl (if they exist)
     - mesh.png as texture.png
     - All .png files in previews/ subdirectory
     - quality.json

   - CRITICAL: Call zip_buffer.seek(0) before returning

2. `validate_job_outputs(output_dir: Path) -> tuple[bool, list[str]]`:
   - Check output_dir exists
   - Check at least one model directory exists
   - For each model directory, check mesh.glb OR mesh.obj exists
   - Return (is_valid, list of missing items)

3. Exception class `IncompleteResultsError(Exception)` for missing outputs

Handle gracefully:
- Missing optional files (mesh.mtl, mesh.ply) - skip silently
- Missing required files (mesh.glb/obj) - raise IncompleteResultsError
  </action>
  <verify>
python -c "
from pathlib import Path
from app.services.result_packager import create_result_zip, validate_job_outputs
print('Imports OK')
"
  </verify>
  <done>result_packager.py has create_result_zip, validate_job_outputs, IncompleteResultsError</done>
</task>

<task type="auto">
  <name>Task 2: Add download endpoint</name>
  <files>app/api/jobs.py</files>
  <action>
Update app/api/jobs.py to add download endpoint:

1. Add imports:
   - StreamingResponse from fastapi.responses
   - create_result_zip, validate_job_outputs, IncompleteResultsError from app.services.result_packager
   - ErrorCode, make_error_detail from app.api.error_codes (will be created by Plan 01, but can import now)

2. Add GET /{job_id}/download endpoint:

```python
@router.get("/{job_id}/download")
async def download_results(job_id: str):
    """
    Download all job results as a single ZIP file.

    ZIP contains: mesh files (OBJ, PLY, GLB), textures, preview images, quality.json

    Returns:
        StreamingResponse: ZIP file

    Raises:
        HTTPException 404: Job not found (never existed)
        HTTPException 409: Job not completed yet (still processing)
        HTTPException 410: Job results expired/cleaned up
        HTTPException 500: Job failed or outputs incomplete
    """
```

3. Implementation logic:
   a. Get Celery task result: `result = celery_app.AsyncResult(job_id)`

   b. Check job state and return appropriate errors:
      - PENDING: 404 JOB_NOT_FOUND (job never existed or expired from Celery)
      - STARTED/PROGRESS: 409 JOB_NOT_READY with current progress
      - FAILURE: 500 JOB_FAILED with error from result.info
      - REVOKED: 500 JOB_FAILED (cancelled)
      - SUCCESS: continue to download

   c. Check output directory exists:
      - job_path = get_job_path(job_id)
      - output_dir = job_path / "output"
      - If not exists: 410 JOB_EXPIRED

   d. Validate outputs: validate_job_outputs(output_dir)
      - If invalid: 500 INCOMPLETE_RESULTS with missing items

   e. Create ZIP: create_result_zip(job_id, output_dir)

   f. Return StreamingResponse:
      ```python
      return StreamingResponse(
          zip_buffer,
          media_type="application/zip",
          headers={"Content-Disposition": f"attachment; filename={job_id}.zip"}
      )
      ```

4. Use structured errors via HTTPException with detail=make_error_detail(...) pattern

Note: If error_codes.py doesn't exist yet (Plan 01 not run), create a minimal version or use dict literals for now. The plans can run in parallel in Wave 1.
  </action>
  <verify>
# Start FastAPI in test mode and check endpoint exists
python -c "
from app.main import app
from fastapi.routing import APIRoute
routes = [r for r in app.routes if isinstance(r, APIRoute)]
download_routes = [r for r in routes if 'download' in r.path]
print(f'Download routes: {[r.path for r in download_routes]}')
assert any('download' in r.path for r in routes), 'Download endpoint not found'
print('OK')
"
  </verify>
  <done>GET /jobs/{job_id}/download endpoint exists, returns StreamingResponse for completed jobs, structured errors for all failure cases</done>
</task>

</tasks>

<verification>
1. Import test: `python -c "from app.services.result_packager import create_result_zip, validate_job_outputs"`
2. Endpoint exists: Check app routes include /jobs/{job_id}/download
3. Unit tests pass: `pytest tests/ -v --tb=short`
</verification>

<success_criteria>
- create_result_zip creates valid ZIP with correct structure
- validate_job_outputs detects missing required files
- Download endpoint returns ZIP for completed jobs
- Download endpoint returns 404/409/410/500 for appropriate states
- Response includes Content-Disposition header with filename
</success_criteria>

<output>
After completion, create `.planning/phases/05-results-error-handling/05-02-SUMMARY.md`
</output>
